{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "!pip install -qU langchain langchain_community"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:49:37.716697Z",
     "start_time": "2024-10-01T07:49:22.206037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\r\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.6/5.6 MB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in ./venv/lib/python3.9/site-packages (from pdfminer.six) (3.3.2)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./venv/lib/python3.9/site-packages (from pdfminer.six) (43.0.1)\r\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\r\n",
      "Installing collected packages: pdfminer.six\r\n",
      "Successfully installed pdfminer.six-20240706\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer.six"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:58:29.082938Z",
     "start_time": "2024-10-01T07:58:25.211656Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain_chroma\n",
    "!pip install -qU langchain_ollama"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:50:21.838569Z",
     "start_time": "2024-10-01T07:49:42.454665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.6\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:50:26.799798Z",
     "start_time": "2024-10-01T07:50:26.676429Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:51:08.307234Z",
     "start_time": "2024-10-01T07:51:03.453578Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\r\n",
      "  Using cached unstructured-0.15.13-py3-none-any.whl (2.1 MB)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from unstructured) (4.66.5)\r\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.9/site-packages (from unstructured) (4.12.3)\r\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.9/site-packages (from unstructured) (4.12.2)\r\n",
      "Collecting langdetect\r\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting tabulate\r\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\r\n",
      "Collecting python-oxmsg\r\n",
      "  Using cached python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\r\n",
      "Collecting python-magic\r\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\r\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.9/site-packages (from unstructured) (0.6.7)\r\n",
      "Requirement already satisfied: backoff in ./venv/lib/python3.9/site-packages (from unstructured) (2.2.1)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from unstructured) (2.32.3)\r\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.9/site-packages (from unstructured) (1.16.0)\r\n",
      "Collecting filetype\r\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\r\n",
      "Collecting chardet\r\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",
      "Collecting nltk\r\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\r\n",
      "Collecting rapidfuzz\r\n",
      "  Downloading rapidfuzz-3.10.0-cp39-cp39-macosx_11_0_arm64.whl (1.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting unstructured-client\r\n",
      "  Using cached unstructured_client-0.25.9-py3-none-any.whl (45 kB)\r\n",
      "Collecting python-iso639\r\n",
      "  Using cached python_iso639-2024.4.27-py3-none-any.whl (274 kB)\r\n",
      "Requirement already satisfied: numpy<2 in ./venv/lib/python3.9/site-packages (from unstructured) (1.26.4)\r\n",
      "Collecting emoji\r\n",
      "  Using cached emoji-2.13.2-py3-none-any.whl (553 kB)\r\n",
      "Collecting lxml\r\n",
      "  Downloading lxml-5.3.0-cp39-cp39-macosx_10_9_universal2.whl (8.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.1/8.1 MB\u001B[0m \u001B[31m10.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: psutil in ./venv/lib/python3.9/site-packages (from unstructured) (6.0.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.9/site-packages (from beautifulsoup4->unstructured) (2.6)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.9/site-packages (from dataclasses-json->unstructured) (3.22.0)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.9/site-packages (from dataclasses-json->unstructured) (0.9.0)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from langdetect->unstructured) (1.16.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.9/site-packages (from nltk->unstructured) (2024.9.11)\r\n",
      "Requirement already satisfied: click in ./venv/lib/python3.9/site-packages (from nltk->unstructured) (8.1.7)\r\n",
      "Collecting joblib\r\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\r\n",
      "Collecting olefile\r\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->unstructured) (2024.8.30)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->unstructured) (3.10)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->unstructured) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->unstructured) (2.2.3)\r\n",
      "Collecting cryptography>=3.1\r\n",
      "  Using cached cryptography-43.0.1-cp39-abi3-macosx_10_9_universal2.whl (6.2 MB)\r\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (1.0.0)\r\n",
      "Collecting requests-toolbelt>=1.0.0\r\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (0.27.2)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (1.6.0)\r\n",
      "Requirement already satisfied: packaging>=23.1 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (24.1)\r\n",
      "Collecting deepdiff>=6.0\r\n",
      "  Using cached deepdiff-8.0.1-py3-none-any.whl (82 kB)\r\n",
      "Collecting pypdf>=4.0\r\n",
      "  Using cached pypdf-5.0.1-py3-none-any.whl (294 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (2.9.0.post0)\r\n",
      "Collecting jsonpath-python>=1.0.6\r\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib/python3.9/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\r\n",
      "Collecting orderly-set==5.2.2\r\n",
      "  Using cached orderly_set-5.2.2-py3-none-any.whl (11 kB)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\r\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.6.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\r\n",
      "Building wheels for collected packages: langdetect\r\n",
      "  Building wheel for langdetect (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=0518e11355c8d5dd5d9d7b46d33b13895dc3c1d5667093287d5c649e45cc98a7\r\n",
      "  Stored in directory: /Users/rishavbose/Library/Caches/pip/wheels/6a/67/f8/9cf1a8ff87e0b37f738769df49cc142a655489a6d27b68089f\r\n",
      "Successfully built langdetect\r\n",
      "Installing collected packages: filetype, tabulate, rapidfuzz, python-magic, python-iso639, pypdf, orderly-set, olefile, lxml, langdetect, jsonpath-python, joblib, emoji, chardet, requests-toolbelt, python-oxmsg, nltk, deepdiff, cryptography, unstructured-client, unstructured\r\n",
      "Successfully installed chardet-5.2.0 cryptography-43.0.1 deepdiff-8.0.1 emoji-2.13.2 filetype-1.2.0 joblib-1.4.2 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.3.0 nltk-3.9.1 olefile-0.47 orderly-set-5.2.2 pypdf-5.0.1 python-iso639-2024.4.27 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.10.0 requests-toolbelt-1.0.0 tabulate-0.9.0 unstructured-0.15.13 unstructured-client-0.25.9\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:52:16.314516Z",
     "start_time": "2024-10-01T07:52:05.887457Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer\r\n",
      "  Using cached pdfminer-20191125.tar.gz (4.2 MB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting pycryptodome\r\n",
      "  Using cached pycryptodome-3.20.0-cp35-abi3-macosx_10_9_universal2.whl (2.4 MB)\r\n",
      "Building wheels for collected packages: pdfminer\r\n",
      "  Building wheel for pdfminer (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140071 sha256=6d1796e5f62dfc71e6cb35f0d7caa492e86b64b00d85f441c98059c73e429c67\r\n",
      "  Stored in directory: /Users/rishavbose/Library/Caches/pip/wheels/41/44/38/6f82831ef593d74608e2f3cca841d5b43b8eb31b6cd60560a9\r\n",
      "Successfully built pdfminer\r\n",
      "Installing collected packages: pycryptodome, pdfminer\r\n",
      "Successfully installed pdfminer-20191125 pycryptodome-3.20.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:53:14.879097Z",
     "start_time": "2024-10-01T07:52:50.822284Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured-inference\r\n",
      "  Downloading unstructured_inference-0.7.37-py3-none-any.whl (57 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.6/57.6 kB\u001B[0m \u001B[31m979.2 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting python-multipart\r\n",
      "  Downloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\r\n",
      "Collecting onnx\r\n",
      "  Downloading onnx-1.16.2-cp39-cp39-macosx_11_0_universal2.whl (16.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.5/16.5 MB\u001B[0m \u001B[31m12.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy<2 in ./venv/lib/python3.9/site-packages (from unstructured-inference) (1.26.4)\r\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in ./venv/lib/python3.9/site-packages (from unstructured-inference) (1.19.2)\r\n",
      "Requirement already satisfied: rapidfuzz in ./venv/lib/python3.9/site-packages (from unstructured-inference) (3.10.0)\r\n",
      "Collecting matplotlib\r\n",
      "  Downloading matplotlib-3.9.2-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.8/7.8 MB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hRequirement already satisfied: huggingface-hub in ./venv/lib/python3.9/site-packages (from unstructured-inference) (0.25.1)\r\n",
      "Collecting opencv-python!=4.7.0.68\r\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m54.8/54.8 MB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting layoutparser\r\n",
      "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m19.2/19.2 MB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting torch\r\n",
      "  Downloading torch-2.4.1-cp39-none-macosx_11_0_arm64.whl (62.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.1/62.1 MB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting timm\r\n",
      "  Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting transformers>=4.25.1\r\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.9/9.9 MB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference) (1.13.3)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference) (24.1)\r\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference) (4.25.5)\r\n",
      "Requirement already satisfied: coloredlogs in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference) (15.0.1)\r\n",
      "Requirement already satisfied: flatbuffers in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference) (24.3.25)\r\n",
      "Collecting safetensors>=0.4.1\r\n",
      "  Downloading safetensors-0.4.5-cp39-cp39-macosx_11_0_arm64.whl (383 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m383.2/383.2 kB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference) (4.66.5)\r\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./venv/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference) (0.20.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference) (2024.9.11)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference) (2.32.3)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface-hub->unstructured-inference) (4.12.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface-hub->unstructured-inference) (2024.9.0)\r\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.9/site-packages (from layoutparser->unstructured-inference) (10.4.0)\r\n",
      "Collecting pdfplumber\r\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m59.2/59.2 kB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting scipy\r\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.3/30.3 MB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting pdf2image\r\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\r\n",
      "Collecting pandas\r\n",
      "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.3/11.3 MB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting iopath\r\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.2/42.2 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting kiwisolver>=1.3.1\r\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.3/64.3 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference) (6.4.5)\r\n",
      "Collecting cycler>=0.10\r\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference) (2.9.0.post0)\r\n",
      "Collecting contourpy>=1.0.1\r\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m249.3/249.3 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting fonttools>=4.22.0\r\n",
      "  Downloading fonttools-4.54.1-cp39-cp39-macosx_11_0_arm64.whl (2.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting pyparsing>=2.3.1\r\n",
      "  Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\r\n",
      "Collecting torchvision\r\n",
      "  Downloading torchvision-0.19.1-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch->unstructured-inference) (3.1.4)\r\n",
      "Collecting networkx\r\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->unstructured-inference) (3.20.2)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->unstructured-inference) (1.16.0)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference) (10.0)\r\n",
      "Collecting portalocker\r\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch->unstructured-inference) (2.1.5)\r\n",
      "Collecting pytz>=2020.1\r\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m508.0/508.0 kB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting tzdata>=2022.7\r\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m346.6/346.6 kB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting pypdfium2>=4.18.0\r\n",
      "  Downloading pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.7/2.7 MB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting pdfminer.six==20231228\r\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.6/5.6 MB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: cryptography>=36.0.0 in ./venv/lib/python3.9/site-packages (from pdfminer.six==20231228->pdfplumber->layoutparser->unstructured-inference) (43.0.1)\r\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./venv/lib/python3.9/site-packages (from pdfminer.six==20231228->pdfplumber->layoutparser->unstructured-inference) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->transformers>=4.25.1->unstructured-inference) (2.2.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->transformers>=4.25.1->unstructured-inference) (3.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->transformers>=4.25.1->unstructured-inference) (2024.8.30)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.9/site-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference) (1.3.0)\r\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->layoutparser->unstructured-inference) (1.17.1)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber->layoutparser->unstructured-inference) (2.22)\r\n",
      "Building wheels for collected packages: iopath\r\n",
      "  Building wheel for iopath (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=31d79474120b12ae203bd2a99c7a57b890d47870f6e7878449ca5796939ccbef\r\n",
      "  Stored in directory: /Users/rishavbose/Library/Caches/pip/wheels/2f/ce/ac/07529e6caba9b9c9c78a3cdae0a21c52ed14b37f98599eab74\r\n",
      "Successfully built iopath\r\n",
      "Installing collected packages: pytz, tzdata, scipy, safetensors, python-multipart, pypdfium2, pyparsing, portalocker, pdf2image, opencv-python, onnx, networkx, kiwisolver, fonttools, cycler, contourpy, torch, pandas, matplotlib, iopath, torchvision, pdfminer.six, transformers, timm, pdfplumber, layoutparser, unstructured-inference\r\n",
      "  Attempting uninstall: pdfminer.six\r\n",
      "    Found existing installation: pdfminer.six 20240706\r\n",
      "    Uninstalling pdfminer.six-20240706:\r\n",
      "      Successfully uninstalled pdfminer.six-20240706\r\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 iopath-0.1.10 kiwisolver-1.4.7 layoutparser-0.3.4 matplotlib-3.9.2 networkx-3.2.1 onnx-1.16.2 opencv-python-4.10.0.84 pandas-2.2.3 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.4 portalocker-2.10.1 pyparsing-3.1.4 pypdfium2-4.30.0 python-multipart-0.0.12 pytz-2024.2 safetensors-0.4.5 scipy-1.13.1 timm-1.0.9 torch-2.4.1 torchvision-0.19.1 transformers-4.45.1 tzdata-2024.2 unstructured-inference-0.7.37\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured-inference"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T08:02:42.551962Z",
     "start_time": "2024-10-01T08:01:00.275028Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pi-heif\r\n",
      "  Downloading pi_heif-0.18.0-cp39-cp39-macosx_14_0_arm64.whl (488 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m488.3/488.3 kB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pillow>=10.1.0 in ./venv/lib/python3.9/site-packages (from pi-heif) (10.4.0)\r\n",
      "Installing collected packages: pi-heif\r\n",
      "Successfully installed pi-heif-0.18.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pi-heif"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T08:00:31.602515Z",
     "start_time": "2024-10-01T08:00:28.056261Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow-heif\r\n",
      "  Downloading pillow_heif-0.18.0-cp39-cp39-macosx_14_0_arm64.whl (3.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.7/3.7 MB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting pillow>=10.1.0\r\n",
      "  Downloading pillow-10.4.0-cp39-cp39-macosx_11_0_arm64.whl (3.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m15.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: pillow, pillow-heif\r\n",
      "Successfully installed pillow-10.4.0 pillow-heif-0.18.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow-heif"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:59:13.946127Z",
     "start_time": "2024-10-01T07:59:08.749101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.document_loaders import WebBaseLoader, OnlinePDFLoader\n",
    "import bs4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:44:23.243812Z",
     "start_time": "2024-10-04T06:44:20.018183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:44:23.256105Z",
     "start_time": "2024-10-04T06:44:23.244089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytesseract is not installed. Cannot use the ocr_only partitioning strategy. Falling back to partitioning with another strategy.\n",
      "Falling back to partitioning with hi_res.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m loader \u001B[38;5;241m=\u001B[39m OnlinePDFLoader(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcf-frm.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_community/document_loaders/pdf.py:160\u001B[0m, in \u001B[0;36mOnlinePDFLoader.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load documents.\"\"\"\u001B[39;00m\n\u001B[1;32m    159\u001B[0m loader \u001B[38;5;241m=\u001B[39m UnstructuredPDFLoader(\u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path))\n\u001B[0;32m--> 160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/document_loaders/base.py:31\u001B[0m, in \u001B[0;36mBaseLoader.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Document]:\n\u001B[1;32m     30\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlazy_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_community/document_loaders/unstructured.py:107\u001B[0m, in \u001B[0;36mUnstructuredBaseLoader.lazy_load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlazy_load\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Document]:\n\u001B[1;32m    106\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load file.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 107\u001B[0m     elements \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_elements\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    108\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_process_elements(elements)\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melements\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_community/document_loaders/pdf.py:74\u001B[0m, in \u001B[0;36mUnstructuredPDFLoader._get_elements\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_elements\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munstructured\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpartition\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpdf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m partition_pdf\n\u001B[0;32m---> 74\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpartition_pdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munstructured_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/documents/elements.py:605\u001B[0m, in \u001B[0;36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    603\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    604\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: _P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: _P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Element]:\n\u001B[0;32m--> 605\u001B[0m     elements \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    606\u001B[0m     call_args \u001B[38;5;241m=\u001B[39m get_call_args_applying_defaults(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    608\u001B[0m     regex_metadata: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstr\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m call_args\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregex_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/file_utils/filetype.py:731\u001B[0m, in \u001B[0;36madd_filetype.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    729\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    730\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: _P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: _P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Element]:\n\u001B[0;32m--> 731\u001B[0m     elements \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    732\u001B[0m     params \u001B[38;5;241m=\u001B[39m get_call_args_applying_defaults(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    733\u001B[0m     include_metadata \u001B[38;5;241m=\u001B[39m params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minclude_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/file_utils/filetype.py:687\u001B[0m, in \u001B[0;36madd_metadata.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    685\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    686\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: _P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: _P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Element]:\n\u001B[0;32m--> 687\u001B[0m     elements \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    688\u001B[0m     call_args \u001B[38;5;241m=\u001B[39m get_call_args_applying_defaults(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    689\u001B[0m     include_metadata \u001B[38;5;241m=\u001B[39m call_args\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minclude_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/chunking/dispatch.py:74\u001B[0m, in \u001B[0;36madd_chunking_strategy.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"The decorated function is replaced with this one.\"\"\"\u001B[39;00m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;66;03m# -- call the partitioning function to get the elements --\u001B[39;00m\n\u001B[0;32m---> 74\u001B[0m elements \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;66;03m# -- look for a chunking-strategy argument --\u001B[39;00m\n\u001B[1;32m     77\u001B[0m call_args \u001B[38;5;241m=\u001B[39m get_call_args_applying_defaults(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/partition/pdf.py:205\u001B[0m, in \u001B[0;36mpartition_pdf\u001B[0;34m(filename, file, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, include_metadata, metadata_filename, metadata_last_modified, chunking_strategy, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, starting_page_number, extract_forms, form_extraction_skip_tables, **kwargs)\u001B[0m\n\u001B[1;32m    201\u001B[0m exactly_one(filename\u001B[38;5;241m=\u001B[39mfilename, file\u001B[38;5;241m=\u001B[39mfile)\n\u001B[1;32m    203\u001B[0m languages \u001B[38;5;241m=\u001B[39m check_language_args(languages \u001B[38;5;129;01mor\u001B[39;00m [], ocr_languages)\n\u001B[0;32m--> 205\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpartition_pdf_or_image\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_page_breaks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_page_breaks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_table_structure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_table_structure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlanguages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlanguages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetadata_last_modified\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata_last_modified\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhi_res_model_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhi_res_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_images_in_pdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_images_in_pdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_image_block_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    216\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_image_block_output_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_output_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_image_block_to_payload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_to_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_from_file_object\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_from_file_object\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstarting_page_number\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstarting_page_number\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_forms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_forms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mform_extraction_skip_tables\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mform_extraction_skip_tables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/partition/pdf.py:307\u001B[0m, in \u001B[0;36mpartition_pdf_or_image\u001B[0;34m(filename, file, is_image, include_page_breaks, strategy, infer_table_structure, languages, metadata_last_modified, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, starting_page_number, extract_forms, form_extraction_skip_tables, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n\u001B[1;32m    306\u001B[0m         warnings\u001B[38;5;241m.\u001B[39msimplefilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 307\u001B[0m         elements \u001B[38;5;241m=\u001B[39m \u001B[43m_partition_pdf_or_image_local\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspooled_to_bytes_io_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m            \u001B[49m\u001B[43mis_image\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_image\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m            \u001B[49m\u001B[43minfer_table_structure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_table_structure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m            \u001B[49m\u001B[43minclude_page_breaks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_page_breaks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlanguages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlanguages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m            \u001B[49m\u001B[43mocr_languages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mocr_languages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata_last_modified\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata_last_modified\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mlast_modification_date\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhi_res_model_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhi_res_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpdf_text_extractable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpdf_text_extractable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_images_in_pdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_images_in_pdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_image_block_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_image_block_output_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_output_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_image_block_to_payload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_to_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstarting_page_number\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstarting_page_number\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_forms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_forms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m            \u001B[49m\u001B[43mform_extraction_skip_tables\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mform_extraction_skip_tables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    327\u001B[0m         out_elements \u001B[38;5;241m=\u001B[39m _process_uncategorized_text_elements(elements)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m strategy \u001B[38;5;241m==\u001B[39m PartitionStrategy\u001B[38;5;241m.\u001B[39mFAST:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/utils.py:217\u001B[0m, in \u001B[0;36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: _P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: _P\u001B[38;5;241m.\u001B[39mkwargs):\n\u001B[1;32m    216\u001B[0m     run_check()\n\u001B[0;32m--> 217\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/partition/pdf.py:595\u001B[0m, in \u001B[0;36m_partition_pdf_or_image_local\u001B[0;34m(filename, file, is_image, infer_table_structure, include_page_breaks, languages, ocr_languages, ocr_mode, model_name, hi_res_model_name, pdf_image_dpi, metadata_last_modified, pdf_text_extractable, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, analysis, analyzed_image_output_dir_path, starting_page_number, extract_forms, form_extraction_skip_tables, pdf_hi_res_max_pages, **kwargs)\u001B[0m\n\u001B[1;32m    592\u001B[0m skip_analysis_dump \u001B[38;5;241m=\u001B[39m env_config\u001B[38;5;241m.\u001B[39mANALYSIS_DUMP_OD_SKIP\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 595\u001B[0m     inferred_document_layout \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_file_with_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    597\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_image\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_image\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhi_res_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpdf_image_dpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpdf_image_dpi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    600\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    602\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hi_res_model_name\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchipper\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    603\u001B[0m         \u001B[38;5;66;03m# NOTE(alan): We shouldn't do OCR with chipper\u001B[39;00m\n\u001B[1;32m    604\u001B[0m         \u001B[38;5;66;03m# NOTE(antonio): We shouldn't do PDFMiner with chipper\u001B[39;00m\n\u001B[1;32m    605\u001B[0m         final_document_layout \u001B[38;5;241m=\u001B[39m inferred_document_layout\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/inference/layout.py:376\u001B[0m, in \u001B[0;36mprocess_file_with_model\u001B[0;34m(filename, model_name, is_image, fixed_layouts, pdf_image_dpi, **kwargs)\u001B[0m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsupported model type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(model)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    368\u001B[0m layout \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    369\u001B[0m     DocumentLayout\u001B[38;5;241m.\u001B[39mfrom_image_file(\n\u001B[1;32m    370\u001B[0m         filename,\n\u001B[1;32m    371\u001B[0m         detection_model\u001B[38;5;241m=\u001B[39mdetection_model,\n\u001B[1;32m    372\u001B[0m         element_extraction_model\u001B[38;5;241m=\u001B[39melement_extraction_model,\n\u001B[1;32m    373\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    374\u001B[0m     )\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_image\n\u001B[0;32m--> 376\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[43mDocumentLayout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    378\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdetection_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdetection_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[43melement_extraction_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43melement_extraction_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfixed_layouts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_layouts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpdf_image_dpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpdf_image_dpi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m )\n\u001B[1;32m    385\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m layout\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/inference/layout.py:75\u001B[0m, in \u001B[0;36mDocumentLayout.from_file\u001B[0;34m(cls, filename, fixed_layouts, pdf_image_dpi, **kwargs)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (image_path, fixed_layout) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(image_paths, fixed_layouts)):\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;66;03m# NOTE(robinson) - In the future, maybe we detect the page number and default\u001B[39;00m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;66;03m# to the index if it is not detected\u001B[39;00m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Image\u001B[38;5;241m.\u001B[39mopen(image_path) \u001B[38;5;28;01mas\u001B[39;00m image:\n\u001B[0;32m---> 75\u001B[0m         page \u001B[38;5;241m=\u001B[39m \u001B[43mPageLayout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_image\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnumber\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdocument_filename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfixed_layout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_layout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m         pages\u001B[38;5;241m.\u001B[39mappend(page)\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_pages(pages)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/inference/layout.py:307\u001B[0m, in \u001B[0;36mPageLayout.from_image\u001B[0;34m(cls, image, image_path, document_filename, number, detection_model, element_extraction_model, fixed_layout)\u001B[0m\n\u001B[1;32m    305\u001B[0m     page\u001B[38;5;241m.\u001B[39mget_elements_using_image_extraction()\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m fixed_layout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 307\u001B[0m     \u001B[43mpage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_elements_with_detection_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    309\u001B[0m     page\u001B[38;5;241m.\u001B[39melements \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/inference/layout.py:190\u001B[0m, in \u001B[0;36mPageLayout.get_elements_with_detection_model\u001B[0;34m(self, inplace, array_only)\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;66;03m# NOTE(mrobinson) - We'll want make this model inference step some kind of\u001B[39;00m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;66;03m# remote call in the future.\u001B[39;00m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 190\u001B[0m inferred_layout: LayoutElements \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetection_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    191\u001B[0m inferred_layout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdetection_model\u001B[38;5;241m.\u001B[39mdeduplicate_detected_elements(\n\u001B[1;32m    192\u001B[0m     inferred_layout,\n\u001B[1;32m    193\u001B[0m )\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/models/unstructuredmodel.py:64\u001B[0m, in \u001B[0;36mUnstructuredObjectDetectionModel.__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Image) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LayoutElements:\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Inference using function call interface.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/models/unstructuredmodel.py:45\u001B[0m, in \u001B[0;36mUnstructuredModel.__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m     44\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Inference using function call interface.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/models/yolox.py:69\u001B[0m, in \u001B[0;36mUnstructuredYoloXModel.predict\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Predict using YoloX model.\"\"\"\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mpredict(x)\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_processing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/models/yolox.py:114\u001B[0m, in \u001B[0;36mUnstructuredYoloXModel.image_processing\u001B[0;34m(self, image)\u001B[0m\n\u001B[1;32m    111\u001B[0m session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m    113\u001B[0m ort_inputs \u001B[38;5;241m=\u001B[39m {session\u001B[38;5;241m.\u001B[39mget_inputs()[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mname: img[\u001B[38;5;28;01mNone\u001B[39;00m, :, :, :]}\n\u001B[0;32m--> 114\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mort_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;66;03m# TODO(benjamin): check for p6\u001B[39;00m\n\u001B[1;32m    116\u001B[0m predictions \u001B[38;5;241m=\u001B[39m demo_postprocess(output[\u001B[38;5;241m0\u001B[39m], input_shape, p6\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, output_names, input_feed, run_options)\u001B[0m\n\u001B[1;32m    218\u001B[0m     output_names \u001B[38;5;241m=\u001B[39m [output\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs_meta]\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_feed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m C\u001B[38;5;241m.\u001B[39mEPFail \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_fallback:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# loader = OnlinePDFLoader(\"cf-frm.pdf\")\n",
    "# data = loader.load()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T08:39:11.531036Z",
     "start_time": "2024-10-01T08:36:22.018978Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytesseract is not installed. Cannot use the ocr_only partitioning strategy. Falling back to partitioning with another strategy.\n",
      "Falling back to partitioning with hi_res.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_community\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdocument_loaders\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m UnstructuredPDFLoader\n\u001B[1;32m      3\u001B[0m loader \u001B[38;5;241m=\u001B[39m UnstructuredPDFLoader(\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcf-frm.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melements\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      5\u001B[0m )\n\u001B[0;32m----> 6\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/document_loaders/base.py:31\u001B[0m, in \u001B[0;36mBaseLoader.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Document]:\n\u001B[1;32m     30\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlazy_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_community/document_loaders/unstructured.py:107\u001B[0m, in \u001B[0;36mUnstructuredBaseLoader.lazy_load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlazy_load\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Document]:\n\u001B[1;32m    106\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load file.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 107\u001B[0m     elements \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_elements\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    108\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_process_elements(elements)\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melements\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_community/document_loaders/pdf.py:74\u001B[0m, in \u001B[0;36mUnstructuredPDFLoader._get_elements\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_elements\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munstructured\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpartition\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpdf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m partition_pdf\n\u001B[0;32m---> 74\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpartition_pdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munstructured_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/documents/elements.py:605\u001B[0m, in \u001B[0;36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    603\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    604\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: _P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: _P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Element]:\n\u001B[0;32m--> 605\u001B[0m     elements \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    606\u001B[0m     call_args \u001B[38;5;241m=\u001B[39m get_call_args_applying_defaults(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    608\u001B[0m     regex_metadata: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstr\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m call_args\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregex_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/file_utils/filetype.py:731\u001B[0m, in \u001B[0;36madd_filetype.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    729\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    730\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: _P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: _P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Element]:\n\u001B[0;32m--> 731\u001B[0m     elements \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    732\u001B[0m     params \u001B[38;5;241m=\u001B[39m get_call_args_applying_defaults(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    733\u001B[0m     include_metadata \u001B[38;5;241m=\u001B[39m params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minclude_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/file_utils/filetype.py:687\u001B[0m, in \u001B[0;36madd_metadata.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    685\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    686\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: _P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: _P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Element]:\n\u001B[0;32m--> 687\u001B[0m     elements \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    688\u001B[0m     call_args \u001B[38;5;241m=\u001B[39m get_call_args_applying_defaults(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    689\u001B[0m     include_metadata \u001B[38;5;241m=\u001B[39m call_args\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minclude_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/chunking/dispatch.py:74\u001B[0m, in \u001B[0;36madd_chunking_strategy.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"The decorated function is replaced with this one.\"\"\"\u001B[39;00m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;66;03m# -- call the partitioning function to get the elements --\u001B[39;00m\n\u001B[0;32m---> 74\u001B[0m elements \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;66;03m# -- look for a chunking-strategy argument --\u001B[39;00m\n\u001B[1;32m     77\u001B[0m call_args \u001B[38;5;241m=\u001B[39m get_call_args_applying_defaults(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/partition/pdf.py:205\u001B[0m, in \u001B[0;36mpartition_pdf\u001B[0;34m(filename, file, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, include_metadata, metadata_filename, metadata_last_modified, chunking_strategy, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, starting_page_number, extract_forms, form_extraction_skip_tables, **kwargs)\u001B[0m\n\u001B[1;32m    201\u001B[0m exactly_one(filename\u001B[38;5;241m=\u001B[39mfilename, file\u001B[38;5;241m=\u001B[39mfile)\n\u001B[1;32m    203\u001B[0m languages \u001B[38;5;241m=\u001B[39m check_language_args(languages \u001B[38;5;129;01mor\u001B[39;00m [], ocr_languages)\n\u001B[0;32m--> 205\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpartition_pdf_or_image\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_page_breaks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_page_breaks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_table_structure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_table_structure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlanguages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlanguages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetadata_last_modified\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata_last_modified\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhi_res_model_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhi_res_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_images_in_pdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_images_in_pdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_image_block_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    216\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_image_block_output_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_output_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_image_block_to_payload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_to_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_from_file_object\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_from_file_object\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstarting_page_number\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstarting_page_number\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_forms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_forms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mform_extraction_skip_tables\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mform_extraction_skip_tables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/partition/pdf.py:307\u001B[0m, in \u001B[0;36mpartition_pdf_or_image\u001B[0;34m(filename, file, is_image, include_page_breaks, strategy, infer_table_structure, languages, metadata_last_modified, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, date_from_file_object, starting_page_number, extract_forms, form_extraction_skip_tables, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n\u001B[1;32m    306\u001B[0m         warnings\u001B[38;5;241m.\u001B[39msimplefilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 307\u001B[0m         elements \u001B[38;5;241m=\u001B[39m \u001B[43m_partition_pdf_or_image_local\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    309\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspooled_to_bytes_io_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m            \u001B[49m\u001B[43mis_image\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_image\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m            \u001B[49m\u001B[43minfer_table_structure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_table_structure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m            \u001B[49m\u001B[43minclude_page_breaks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_page_breaks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlanguages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlanguages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m            \u001B[49m\u001B[43mocr_languages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mocr_languages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata_last_modified\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata_last_modified\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mlast_modification_date\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhi_res_model_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhi_res_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpdf_text_extractable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpdf_text_extractable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_images_in_pdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_images_in_pdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_image_block_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_image_block_output_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_output_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_image_block_to_payload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_image_block_to_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstarting_page_number\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstarting_page_number\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextract_forms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextract_forms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m            \u001B[49m\u001B[43mform_extraction_skip_tables\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mform_extraction_skip_tables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    327\u001B[0m         out_elements \u001B[38;5;241m=\u001B[39m _process_uncategorized_text_elements(elements)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m strategy \u001B[38;5;241m==\u001B[39m PartitionStrategy\u001B[38;5;241m.\u001B[39mFAST:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/utils.py:217\u001B[0m, in \u001B[0;36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: _P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: _P\u001B[38;5;241m.\u001B[39mkwargs):\n\u001B[1;32m    216\u001B[0m     run_check()\n\u001B[0;32m--> 217\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured/partition/pdf.py:595\u001B[0m, in \u001B[0;36m_partition_pdf_or_image_local\u001B[0;34m(filename, file, is_image, infer_table_structure, include_page_breaks, languages, ocr_languages, ocr_mode, model_name, hi_res_model_name, pdf_image_dpi, metadata_last_modified, pdf_text_extractable, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, analysis, analyzed_image_output_dir_path, starting_page_number, extract_forms, form_extraction_skip_tables, pdf_hi_res_max_pages, **kwargs)\u001B[0m\n\u001B[1;32m    592\u001B[0m skip_analysis_dump \u001B[38;5;241m=\u001B[39m env_config\u001B[38;5;241m.\u001B[39mANALYSIS_DUMP_OD_SKIP\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 595\u001B[0m     inferred_document_layout \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_file_with_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    597\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_image\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_image\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhi_res_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpdf_image_dpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpdf_image_dpi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    600\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    602\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hi_res_model_name\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchipper\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    603\u001B[0m         \u001B[38;5;66;03m# NOTE(alan): We shouldn't do OCR with chipper\u001B[39;00m\n\u001B[1;32m    604\u001B[0m         \u001B[38;5;66;03m# NOTE(antonio): We shouldn't do PDFMiner with chipper\u001B[39;00m\n\u001B[1;32m    605\u001B[0m         final_document_layout \u001B[38;5;241m=\u001B[39m inferred_document_layout\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/inference/layout.py:376\u001B[0m, in \u001B[0;36mprocess_file_with_model\u001B[0;34m(filename, model_name, is_image, fixed_layouts, pdf_image_dpi, **kwargs)\u001B[0m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsupported model type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(model)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    368\u001B[0m layout \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    369\u001B[0m     DocumentLayout\u001B[38;5;241m.\u001B[39mfrom_image_file(\n\u001B[1;32m    370\u001B[0m         filename,\n\u001B[1;32m    371\u001B[0m         detection_model\u001B[38;5;241m=\u001B[39mdetection_model,\n\u001B[1;32m    372\u001B[0m         element_extraction_model\u001B[38;5;241m=\u001B[39melement_extraction_model,\n\u001B[1;32m    373\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    374\u001B[0m     )\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_image\n\u001B[0;32m--> 376\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[43mDocumentLayout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    378\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdetection_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdetection_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[43melement_extraction_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43melement_extraction_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfixed_layouts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_layouts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpdf_image_dpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpdf_image_dpi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m )\n\u001B[1;32m    385\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m layout\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/inference/layout.py:75\u001B[0m, in \u001B[0;36mDocumentLayout.from_file\u001B[0;34m(cls, filename, fixed_layouts, pdf_image_dpi, **kwargs)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (image_path, fixed_layout) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(image_paths, fixed_layouts)):\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;66;03m# NOTE(robinson) - In the future, maybe we detect the page number and default\u001B[39;00m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;66;03m# to the index if it is not detected\u001B[39;00m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Image\u001B[38;5;241m.\u001B[39mopen(image_path) \u001B[38;5;28;01mas\u001B[39;00m image:\n\u001B[0;32m---> 75\u001B[0m         page \u001B[38;5;241m=\u001B[39m \u001B[43mPageLayout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_image\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnumber\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdocument_filename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfixed_layout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_layout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m         pages\u001B[38;5;241m.\u001B[39mappend(page)\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrom_pages(pages)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/inference/layout.py:307\u001B[0m, in \u001B[0;36mPageLayout.from_image\u001B[0;34m(cls, image, image_path, document_filename, number, detection_model, element_extraction_model, fixed_layout)\u001B[0m\n\u001B[1;32m    305\u001B[0m     page\u001B[38;5;241m.\u001B[39mget_elements_using_image_extraction()\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m fixed_layout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 307\u001B[0m     \u001B[43mpage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_elements_with_detection_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    309\u001B[0m     page\u001B[38;5;241m.\u001B[39melements \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/inference/layout.py:190\u001B[0m, in \u001B[0;36mPageLayout.get_elements_with_detection_model\u001B[0;34m(self, inplace, array_only)\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;66;03m# NOTE(mrobinson) - We'll want make this model inference step some kind of\u001B[39;00m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;66;03m# remote call in the future.\u001B[39;00m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 190\u001B[0m inferred_layout: LayoutElements \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetection_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    191\u001B[0m inferred_layout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdetection_model\u001B[38;5;241m.\u001B[39mdeduplicate_detected_elements(\n\u001B[1;32m    192\u001B[0m     inferred_layout,\n\u001B[1;32m    193\u001B[0m )\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/models/unstructuredmodel.py:64\u001B[0m, in \u001B[0;36mUnstructuredObjectDetectionModel.__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Image) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LayoutElements:\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Inference using function call interface.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/models/unstructuredmodel.py:45\u001B[0m, in \u001B[0;36mUnstructuredModel.__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m     44\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Inference using function call interface.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/models/yolox.py:69\u001B[0m, in \u001B[0;36mUnstructuredYoloXModel.predict\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Predict using YoloX model.\"\"\"\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mpredict(x)\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_processing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/unstructured_inference/models/yolox.py:114\u001B[0m, in \u001B[0;36mUnstructuredYoloXModel.image_processing\u001B[0;34m(self, image)\u001B[0m\n\u001B[1;32m    111\u001B[0m session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m    113\u001B[0m ort_inputs \u001B[38;5;241m=\u001B[39m {session\u001B[38;5;241m.\u001B[39mget_inputs()[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mname: img[\u001B[38;5;28;01mNone\u001B[39;00m, :, :, :]}\n\u001B[0;32m--> 114\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mort_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;66;03m# TODO(benjamin): check for p6\u001B[39;00m\n\u001B[1;32m    116\u001B[0m predictions \u001B[38;5;241m=\u001B[39m demo_postprocess(output[\u001B[38;5;241m0\u001B[39m], input_shape, p6\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001B[0m, in \u001B[0;36mSession.run\u001B[0;34m(self, output_names, input_feed, run_options)\u001B[0m\n\u001B[1;32m    218\u001B[0m     output_names \u001B[38;5;241m=\u001B[39m [output\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs_meta]\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_feed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m C\u001B[38;5;241m.\u001B[39mEPFail \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_fallback:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "#\n",
    "# loader = UnstructuredPDFLoader(\n",
    "#     \"cf-frm.pdf\", mode=\"elements\"\n",
    "# )\n",
    "# data = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:18:18.820777Z",
     "start_time": "2024-10-01T10:16:49.511723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T08:40:44.745972Z",
     "start_time": "2024-10-01T08:40:44.742657Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=512, chunk_overlap=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Using PyPDFLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet pypdf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T08:48:48.238962Z",
     "start_time": "2024-10-01T08:48:44.679533Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "file_path = \"Mahindra_dg.pdf\"\n",
    "loader = PyPDFLoader(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:30:45.895538Z",
     "start_time": "2024-10-01T14:30:45.887812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "data = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:30:47.504128Z",
     "start_time": "2024-10-01T14:30:47.462071Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.voaux.com\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=\"div\"\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T06:16:39.292177Z",
     "start_time": "2024-10-02T06:16:39.060661Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "dd = loader.scrape()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T06:16:58.705565Z",
     "start_time": "2024-10-02T06:16:58.639952Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T06:17:01.916228Z",
     "start_time": "2024-10-02T06:17:01.911293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(metadata={'source': 'https://www.voaux.com'}, page_content='')]"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T06:17:05.934771Z",
     "start_time": "2024-10-02T06:17:05.928585Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "loader2 = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader2.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:16:41.477003Z",
     "start_time": "2024-10-01T10:16:40.787889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:16:43.033728Z",
     "start_time": "2024-10-01T10:16:43.027941Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.')"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:01:43.071778Z",
     "start_time": "2024-10-01T10:01:43.059840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(metadata={'source': 'Mahindra_dg.pdf', 'page': 0}, page_content='MAHINDRA & MAHINDRA LTD.\\nIntegrated Annual Report 2023-24168\\nRaw materials and bought out components \\nas a % of cost of materials consumed\\nFinished goods and Stock-in-trade as a % \\nof sales of products4.8%\\n5.3%F24\\n7.0%\\n4.4%F23INVENTORIES\\nRaw materials and bought out components as a percentage of cost \\nof materials consumed has decreased mainly on account of build-up \\nof inventory last year due to BS6.2 Transition, Shortage of critical \\ncomponents, which has been brought under control during the year \\nwith various initiatives taken by the management. However, finished \\ngoods and stock-in-trade as a percentage of sales of products has \\nincreased mainly due to build up of inventory for on account of new \\nproduct launches and for the upcoming seasons.\\nTRADE RECEIVABLE\\nst stTrade Receivables are Rs. 4,549 crores as at 31 March, 2024, as compared to Rs. 4,042 crores as at 31  March, 2023.  As a percentage of revenue \\nstfrom sales of products and services, trade receivables are lower at 4.7% as at 31  March, 2024, as compared to 4.9% for the previous year mainly \\non account of better collection efforts and higher volume.\\nParticulars\\n94,972\\n1,923\\n1,868\\n2,456\\n1,01,219\\n1,93882,032\\n1,219\\n1,709\\n1,684\\n86,644\\n92493.8\\n1.9\\n1.9\\n2.4\\n100.0\\n1.994.7\\n1.4\\n2.0\\n1.9\\n100.0\\n1.115.8\\n57.8\\n9.3\\n45.8\\n16.8\\n109.9F24\\nAmount Amount% to Income\\nfrom Operations% to Income\\nfrom Operations %Increase F23\\nSales of products \\nSale of services\\nOther operating revenue\\nIncome from investment related to \\nsubsidiaries, associates, and joint ventures\\nIncome from operations\\nOther income(Rs. crores)RESULTS OF OPERATIONS\\nINCOME\\nINCOME FROM OPERATIONS \\nThe net sales and income from operations of the Company increased by 16.8% as compared to the previous year mainly driven by performance of \\nthe Auto business. \\nSales volume in Auto segment witnessed an increase of 11.7% clocking 7,80,475 vehicles in the current year from 6,98,456 vehicles in the \\nprevious year. \\nIncrease in volumes combined with higher realisation and increase in investment related income from subsidiaries, associates, and joint ventures \\nled to Income from operations growing by 16.8% as compared to the previous year.\\nstOther income during the year ended 31  March, 2024 at Rs. 1,938 crores is higher than Rs. 924 crores earned in the previous year mainly on \\naccount of higher fair value gain on certain non-current investment in the current year.')]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:30:53.691493Z",
     "start_time": "2024-10-01T14:30:53.681680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=512, chunk_overlap=0\n",
    ")\n",
    "splits = text_splitter.split_documents(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:28:39.444008Z",
     "start_time": "2024-10-01T10:28:39.259338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(metadata={'source': 'mahindra_report.pdf', 'page': 174}, page_content=\"167MANAGEMENT DISCUSSION\\nAND ANALYSIS\\nThe framework is a combination \\nof entity-level controls (including \\nEnterprise Risk Management, \\nLegal Compliance Framework, \\nInternal Audit and Anti-Fraud \\nMechanisms such as Ethics \\nFramework, Code of Conduct, \\nWhistle-Blower Policy, etc.), \\nprocess level controls, information \\ntechnology-based controls, period \\nend ﬁnancial reporting and closing \\ncontrols.\\nFurther, the Internal Control Systems have been designed to provide \\nreasonable assurance with regard to recording and providing reliable \\nfinancial and operational information. In the highly networked IT \\nenvironment of the Company, validation of IT Security receives \\nfocussed attention from IT specialists and Statutory Auditors.\\nThe Chief Internal Auditor reports administratively to the Chairman \\nof the Board and functionally to the Audit Committee. The Internal \\nAudit function develops an audit plan for the Company, which covers, \\ninter alia, corporate, core business operations, as well as support \\nfunctions. The Audit Committee reviews the annual internal audit \\nplan. Significant audit observations are presented to the Audit \\nCommittee, together with the status of the management actions \\nand the progress of the implementation of the recommendations.\\nThe Audit Committee reviews the adequacy and effectiveness of the \\nCompany's internal control environment and monitors the \\nimplementation of audit recommendations. During the year, the \\nCompany has taken steps to review and document the adequacy and \\noperating effectiveness of internal controls. Nonetheless, your \\nCompany recognises that any internal control framework, no matter \\nhow well designed, has inherent limitations and accordingly, regular \\naudits and review processes ensure that such systems are reinforced \\non an ongoing basis.\\nYour Company's Management has carried out the evaluation of \\ndesign and operative effectiveness of these controls and noted no \\nsignificant deficiencies/material weaknesses that might impact \\nfinancial statements as at the Balance Sheet date.DISCUSSION ON FINANCIAL\\nPERFORMANCE WITH\\nRESPECT TO OPERATIONAL\\nPERFORMANCE\\nOVERVIEW\\nThe financial statements have been prepared in accordance with Ind \\nAS as per the Companies (Indian Accounting Standards) Rules, 2015 \\nas amended and notified under Section 133 of the Companies Act, \\n2013 ( the Act') and other relevant provisions of the Act. '\\nThe Group's consolidated financial statements have been prepared\\nin compliance with Ind AS 110 on Consolidation of Accounts and \\npresented in a separate section. \\nFINANCIAL INFORMATION\\n[STANDALONE]\\nPROPERTY, PLANT AND EQUIPMENT\\nAND INTANGIBLE ASSETS\\nstAs at 31  March, 2024, the Property, Plant and Equipment and \\nIntangible Assets stood at Rs. 21,284 crores as compared to Rs. \\nst19,761 crores as at 31  March, 2023. During the year, the Company \\nincurred capital expenditure of Rs. 5,029 crores (previous year Rs. \\n4,354 crores). The majority capital expenditure was on new product \\ndevelopment and capacity enhancement.\\nLong-term borrowings\\nShort-term borrowings\\nUnclaimed matured deposits\\nTotal1,135\\n450\\n0 \\n1,585F24\\n(1,197)\\n(1,862)\\n0\\n(3,059)Decrease\\n2,332 \\n2,312\\n0 \\n4,644F23(Rs. crores)\\nBorrowingsBORROWINGS\\nBorrowings have decreased from Rs. 4,644 crores in the previous \\nyear to Rs. 1,585 crores in the current year mainly due to \\nrepayments in the current year.INTERNAL CONTROL SYSTEMS\\nYour Company maintains adequate internal control systems \\ncommensurate with the nature of its business and size and \\ncomplexity of its operations. These are regularly tested for their \\neffectiveness by Statutory as well as Management Auditors. Your \\nCompany's Internal Financial Controls are deployed through the \\nInternal Control - Integrated Framework (2013) issued by the \\nCommittee of Sponsoring Organisations of the Treadway \\nCommission (COSO), that addresses material risks in your Company's \\noperations and Financial reporting objectives.\")"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[172]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:30:51.442221Z",
     "start_time": "2024-10-01T10:30:51.439738Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(metadata={'source': 'cf-frm.pdf', 'page': 0}, page_content='Disclaimer: This Manual was originally prepared by the staff of the Division of Corporation Finance to \\nserve as internal guidance. In 2008, in an effort to increase transparency of informal staff interpretations, the Division posted a version of the Manual to its website. Because of its informal nature, the Manual does not necessarily contain a discussion of all material considerations necessary to reach an accounting or disclosure conclusion. Such conclusions about a particular transaction are very fact dependent and require careful analysis of the transaction and of the relevant authoritative accounting literature and Commission requirements. The information in this Manual is non-authoritative. If it conflicts with authoritative or source material, the authoritative or source material governs. The information presented also may not reflect the views of other Divisions and Offices at the Commission. The guidance is not a rule, regulation or statement of the Commission and the Commission has neither approved nor disapproved this information. The information included in this Manual may be updated from time to time and positions may change. As a result, the information in this manual may not be current.Financial Reporting ManualDivision of Corporation Finance')"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:19:00.581024Z",
     "start_time": "2024-10-01T10:19:00.574872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory')"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:19:52.950893Z",
     "start_time": "2024-10-01T10:19:52.944359Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "datas = []\n",
    "datas.append(data)\n",
    "datas.append(splits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:07:12.170886Z",
     "start_time": "2024-10-01T10:07:12.160123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "join_data = data + splits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:22:41.637274Z",
     "start_time": "2024-10-01T10:22:41.631516Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=join_data, embedding=OpenAIEmbeddings())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:22:52.335944Z",
     "start_time": "2024-10-01T10:22:44.539072Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishavbose/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T10:04:12.602839Z",
     "start_time": "2024-10-02T10:04:11.042295Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#using amazon textract"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Collecting amazon-textract-textractor\r\n",
      "  Downloading amazon_textract_textractor-1.8.3-py3-none-any.whl (308 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m308.4/308.4 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting XlsxWriter<4,>=3.0\r\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m159.9/159.9 kB\u001B[0m \u001B[31m13.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: Pillow in ./venv/lib/python3.9/site-packages (from amazon-textract-textractor) (10.4.0)\r\n",
      "Collecting editdistance<0.9,>=0.6.2\r\n",
      "  Downloading editdistance-0.8.1-cp39-cp39-macosx_11_0_arm64.whl (79 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.1/79.1 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: amazon-textract-caller<1,>=0.2.4 in ./venv/lib/python3.9/site-packages (from amazon-textract-textractor) (0.2.4)\r\n",
      "Requirement already satisfied: tabulate<0.10,>=0.9 in ./venv/lib/python3.9/site-packages (from amazon-textract-textractor) (0.9.0)\r\n",
      "Requirement already satisfied: boto3>=1.26.35 in ./venv/lib/python3.9/site-packages (from amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.35.30)\r\n",
      "Requirement already satisfied: amazon-textract-response-parser>=0.1.39 in ./venv/lib/python3.9/site-packages (from amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.0.3)\r\n",
      "Requirement already satisfied: botocore in ./venv/lib/python3.9/site-packages (from amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.35.30)\r\n",
      "Requirement already satisfied: marshmallow<4,>=3.14 in ./venv/lib/python3.9/site-packages (from amazon-textract-response-parser>=0.1.39->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (3.22.0)\r\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in ./venv/lib/python3.9/site-packages (from boto3>=1.26.35->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (0.10.2)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./venv/lib/python3.9/site-packages (from boto3>=1.26.35->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.0.1)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./venv/lib/python3.9/site-packages (from botocore->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (2.9.0.post0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in ./venv/lib/python3.9/site-packages (from botocore->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.26.20)\r\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.9/site-packages (from marshmallow<4,>=3.14->amazon-textract-response-parser>=0.1.39->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (24.1)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore->amazon-textract-caller<1,>=0.2.4->amazon-textract-textractor) (1.16.0)\r\n",
      "Installing collected packages: XlsxWriter, editdistance, amazon-textract-textractor\r\n",
      "Successfully installed XlsxWriter-3.2.0 amazon-textract-textractor-1.8.3 editdistance-0.8.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet  \"amazon-textract-caller>=0.2.0\"\n",
    "!pip install amazon-textract-textractor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T11:18:19.165674Z",
     "start_time": "2024-10-01T11:18:10.834489Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (UnrecognizedClientException) when calling the DetectDocumentText operation: The security token included in the request is invalid.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_community\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdocument_loaders\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AmazonTextractPDFLoader\n\u001B[1;32m      3\u001B[0m loader \u001B[38;5;241m=\u001B[39m AmazonTextractPDFLoader(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMahindra_dg.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m documents \u001B[38;5;241m=\u001B[39m \u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_community/document_loaders/pdf.py:747\u001B[0m, in \u001B[0;36mAmazonTextractPDFLoader.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    745\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Document]:\n\u001B[1;32m    746\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load given path as pages.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlazy_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_community/document_loaders/pdf.py:768\u001B[0m, in \u001B[0;36mAmazonTextractPDFLoader.lazy_load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    761\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m AmazonTextractPDFLoader\u001B[38;5;241m.\u001B[39m_get_number_of_pages(blob) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    762\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    763\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mblob\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is a multi-page document, \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;124m            but not stored on S3. \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m    765\u001B[0m \u001B[38;5;124m            Textract requires multi-page documents to be on S3.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    766\u001B[0m         )\n\u001B[0;32m--> 768\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/document_loaders/base.py:127\u001B[0m, in \u001B[0;36mBaseBlobParser.parse\u001B[0;34m(self, blob)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse\u001B[39m(\u001B[38;5;28mself\u001B[39m, blob: Blob) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Document]:\n\u001B[1;32m    113\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Eagerly parse the blob into a document or documents.\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \n\u001B[1;32m    115\u001B[0m \u001B[38;5;124;03m    This is a convenience method for interactive development environment.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;124;03m        List of documents\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlazy_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_community/document_loaders/parsers/pdf.py:596\u001B[0m, in \u001B[0;36mAmazonTextractPDFParser.lazy_parse\u001B[0;34m(self, blob)\u001B[0m\n\u001B[1;32m    590\u001B[0m     textract_response_json \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtc\u001B[38;5;241m.\u001B[39mcall_textract(\n\u001B[1;32m    591\u001B[0m         input_document\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(blob\u001B[38;5;241m.\u001B[39mpath),  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    592\u001B[0m         features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtextract_features,\n\u001B[1;32m    593\u001B[0m         boto3_textract_client\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mboto3_textract_client,\n\u001B[1;32m    594\u001B[0m     )\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 596\u001B[0m     textract_response_json \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_textract\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    597\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_document\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m    598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtextract_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    599\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcall_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTextract_Call_Mode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFORCE_SYNC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    600\u001B[0m \u001B[43m        \u001B[49m\u001B[43mboto3_textract_client\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mboto3_textract_client\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    601\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    603\u001B[0m document \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtextractor\u001B[38;5;241m.\u001B[39mDocument\u001B[38;5;241m.\u001B[39mopen(textract_response_json)\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, page \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(document\u001B[38;5;241m.\u001B[39mpages):\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/textractcaller/t_call.py:693\u001B[0m, in \u001B[0;36mcall_textract\u001B[0;34m(input_document, features, queries_config, output_config, adapters_config, kms_key_id, job_tag, notification_channel, client_request_token, return_job_id, force_async_api, call_mode, boto3_textract_client, job_done_polling_interval, mime_type)\u001B[0m\n\u001B[1;32m    691\u001B[0m         result_value \u001B[38;5;241m=\u001B[39m textract\u001B[38;5;241m.\u001B[39manalyze_document(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m    692\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 693\u001B[0m         result_value \u001B[38;5;241m=\u001B[39m \u001B[43mtextract\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetect_document_text\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    695\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsupported input_document type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(input_document)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/botocore/client.py:569\u001B[0m, in \u001B[0;36mClientCreator._create_api_method.<locals>._api_call\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    565\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    566\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpy_operation_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m() only accepts keyword arguments.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    567\u001B[0m     )\n\u001B[1;32m    568\u001B[0m \u001B[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001B[39;00m\n\u001B[0;32m--> 569\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_api_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/botocore/client.py:1023\u001B[0m, in \u001B[0;36mBaseClient._make_api_call\u001B[0;34m(self, operation_name, api_params)\u001B[0m\n\u001B[1;32m   1019\u001B[0m     error_code \u001B[38;5;241m=\u001B[39m error_info\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQueryErrorCode\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m error_info\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m   1020\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCode\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1021\u001B[0m     )\n\u001B[1;32m   1022\u001B[0m     error_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mfrom_code(error_code)\n\u001B[0;32m-> 1023\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error_class(parsed_response, operation_name)\n\u001B[1;32m   1024\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parsed_response\n",
      "\u001B[0;31mClientError\u001B[0m: An error occurred (UnrecognizedClientException) when calling the DetectDocumentText operation: The security token included in the request is invalid."
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import AmazonTextractPDFLoader\n",
    "\n",
    "loader = AmazonTextractPDFLoader(\"Mahindra_dg.pdf\")\n",
    "documents = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T11:21:08.400036Z",
     "start_time": "2024-10-01T11:21:04.280633Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[\n",
    "\tHumanMessagePromptTemplate(\n",
    "\t\tprompt=PromptTemplate(\n",
    "\t\t\tinput_variables=['context', 'question'],\n",
    "\t\t\tinput_types={},\n",
    "\t\t\tpartial_variables={},\n",
    "\t\t\ttemplate=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Try to answer in detail in not less than 500 words.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n",
    "\t\t),\n",
    "\tadditional_kwargs={})\n",
    "\t]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:17:37.641140Z",
     "start_time": "2024-10-01T14:17:37.631328Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T10:04:19.455928Z",
     "start_time": "2024-10-02T10:04:19.435708Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A foreign private issuer ceases to be a shell company typically through a reverse acquisition with a private operating company. Following such a transaction, the issuer must file a Form 8-K within four business days that includes specific items and financial statement content as required by a Form 10 initial registration statement. The registrant is then subject to ongoing reporting requirements under Exchange Act rules for annual and quarterly reports."
     ]
    }
   ],
   "source": [
    "\n",
    "for chunk in rag_chain.stream(\"Tell me about the transactions that Result in a Foreign Private Issuer Ceasing to be a Shell Company\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:23:08.055176Z",
     "start_time": "2024-10-01T10:23:04.827729Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Inner Product Search (MIPS) is a technique used to efficiently retrieve the top k nearest neighbors from a database of vector representations based on the maximum inner product. It commonly employs approximate nearest neighbors (ANN) algorithms to balance speed and accuracy, allowing for faster retrieval with a slight loss in precision. This approach is particularly useful in scenarios where quick access to relevant data is critical."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"Help me understand Maximum Inner Product Search in short?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T10:23:24.725661Z",
     "start_time": "2024-10-01T10:23:22.093472Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 18 of Form 20-F establishes essential disclosure requirements for foreign private issuers seeking to report financial information in accordance with U.S. Generally Accepted Accounting Principles (GAAP) and Regulation S-X. It is imperative for these issuers to fully comprehend the specific Accounting Standards Codifications (ASC) that are required to satisfy the basic requirements under Item 18, as this aids in ensuring transparency and comparability for investors.\n",
      "\n",
      "To begin with, Item 18 mandates certain disclosures that are not required under Item 17, which focuses on the reconciliation of financial statements prepared in accordance with other accounting principles to U.S. GAAP. This means that while Item 17 deals primarily with the quantification of differences in accounting principles, practices, and methods between home-country GAAP and U.S. GAAP, Item 18 encompasses a broader range of disclosures.\n",
      "\n",
      "The following ASC codes and their corresponding requirements are crucial for compliance with Item 18:\n",
      "\n",
      "1. **ASC 260 - Earnings Per Share (EPS)**: Issuers must provide reconciliations of the numerators and denominators used in computing both basic and diluted EPS. Additionally, any relevant disclosures related to EPS calculations must be included. This requirement is essential to provide clarity on how earnings per share figures were derived, which is a critical metric for investors assessing company performance.\n",
      "\n",
      "2. **ASC 280 - Segment Reporting**: Companies are required to disclose information about their reportable segments, including the basis of segmentation, profit or loss information, and certain asset disclosures. This enables investors to understand the different segments of the business and their contributions to overall performance.\n",
      "\n",
      "3. **ASC 825 - Financial Instruments**: This ASC requires fair value disclosures, thus necessitating information on how fair value measurements are determined, including the methodologies and assumptions used in deriving these values. Investors benefit from understanding the valuation of financial instruments held by the company.\n",
      "\n",
      "4. **ASC 825-10-50-20 - Concentrations of Credit Risk**: Organizations must disclose any significant concentrations of credit risk that could impact the financial position. This is particularly relevant for assessing potential vulnerabilities in a company's financial health.\n",
      "\n",
      "5. **ASC 320, 321, and 326 - Investment Securities**: These ASCs cover disclosures regarding various investment securities, including the classification, measurement, and impairment of these investments. Providing detailed information about investment securities is crucial for investors to evaluate the risks associated with the issuer's investment portfolio.\n",
      "\n",
      "6. **ASC 815 - Derivatives and Hedging**: Companies are required to disclose information about off-balance-sheet financial instruments, particularly derivatives. This ensures that investors are aware of any risks associated with these instruments that may not be immediately apparent on the balance sheet.\n",
      "\n",
      "7. **ASC 718 - Compensation—Stock Compensation**: This ASC requires disclosures related to stock-based compensation for both employees and non-employees. Detailed information about the nature and terms of stock compensation plans is vital for understanding potential dilution and compensation costs.\n",
      "\n",
      "8. **ASC 715 - Compensation—Retirement Benefits**: Companies must disclose components of pensions and other post-employment benefits. Investors need clarity on the obligations and costs associated with these benefits.\n",
      "\n",
      "9. **ASC 740 - Income Taxes**: This standard mandates disclosures regarding components of tax expense and information on deferred tax liabilities and assets. Understanding the tax position of a company is critical for assessing its future cash flow and profitability.\n",
      "\n",
      "10. **Classification Differences in Comprehensive Income**: Issuers must provide a statement that classifies components"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m rag_chain\u001B[38;5;241m.\u001B[39mstream(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTell me all the ASC required for the basic requirements of Item 18 of Form 20-F\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(chunk, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, flush\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:3403\u001B[0m, in \u001B[0;36mRunnableSequence.stream\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3397\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[1;32m   3398\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3399\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   3400\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3401\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3402\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3403\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(\u001B[38;5;28miter\u001B[39m([\u001B[38;5;28minput\u001B[39m]), config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:3390\u001B[0m, in \u001B[0;36mRunnableSequence.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3384\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m   3385\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3386\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[1;32m   3387\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3388\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3389\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3390\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m   3391\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   3392\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform,\n\u001B[1;32m   3393\u001B[0m         patch_config(config, run_name\u001B[38;5;241m=\u001B[39m(config \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m   3394\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3395\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:2194\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2192\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2193\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 2194\u001B[0m         chunk: Output \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2195\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   2196\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:3353\u001B[0m, in \u001B[0;36mRunnableSequence._transform\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m   3350\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3351\u001B[0m         final_pipeline \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39mtransform(final_pipeline, config)\n\u001B[0;32m-> 3353\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m final_pipeline\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/output_parsers/transform.py:64\u001B[0m, in \u001B[0;36mBaseTransformOutputParser.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Union[\u001B[38;5;28mstr\u001B[39m, BaseMessage]],\n\u001B[1;32m     51\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m     53\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T]:\n\u001B[1;32m     54\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Transform the input into the output format.\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;124;03m        The transformed output.\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m     65\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform, config, run_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparser\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     66\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:2194\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2192\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2193\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 2194\u001B[0m         chunk: Output \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2195\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   2196\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/output_parsers/transform.py:29\u001B[0m, in \u001B[0;36mBaseTransformOutputParser._transform\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Iterator[Union[\u001B[38;5;28mstr\u001B[39m, BaseMessage]]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T]:\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28minput\u001B[39m:\n\u001B[1;32m     30\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunk, BaseMessage):\n\u001B[1;32m     31\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparse_result([ChatGeneration(message\u001B[38;5;241m=\u001B[39mchunk)])\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:1428\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1425\u001B[0m             final \u001B[38;5;241m=\u001B[39m ichunk\n\u001B[1;32m   1427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m got_first_val:\n\u001B[0;32m-> 1428\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(final, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:418\u001B[0m, in \u001B[0;36mBaseChatModel.stream\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    412\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(\n\u001B[1;32m    413\u001B[0m         e,\n\u001B[1;32m    414\u001B[0m         response\u001B[38;5;241m=\u001B[39mLLMResult(\n\u001B[1;32m    415\u001B[0m             generations\u001B[38;5;241m=\u001B[39m[[generation]] \u001B[38;5;28;01mif\u001B[39;00m generation \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m    416\u001B[0m         ),\n\u001B[1;32m    417\u001B[0m     )\n\u001B[0;32m--> 418\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    420\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_end(LLMResult(generations\u001B[38;5;241m=\u001B[39m[[generation]]))\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:398\u001B[0m, in \u001B[0;36mBaseChatModel.stream\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    395\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrate_limiter\u001B[38;5;241m.\u001B[39macquire(blocking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    397\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 398\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    399\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m chunk\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mid \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    400\u001B[0m             chunk\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mid \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_manager\u001B[38;5;241m.\u001B[39mrun_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:642\u001B[0m, in \u001B[0;36mBaseChatOpenAI._stream\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m response:\n\u001B[1;32m    641\u001B[0m     is_first_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 642\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m response:\n\u001B[1;32m    643\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunk, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    644\u001B[0m             chunk \u001B[38;5;241m=\u001B[39m chunk\u001B[38;5;241m.\u001B[39mmodel_dump()\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:46\u001B[0m, in \u001B[0;36mStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[_T]:\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator:\n\u001B[1;32m     47\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m item\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:58\u001B[0m, in \u001B[0;36mStream.__stream__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m process_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39m_process_response_data\n\u001B[1;32m     56\u001B[0m iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_events()\n\u001B[0;32m---> 58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sse \u001B[38;5;129;01min\u001B[39;00m iterator:\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sse\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[DONE]\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     60\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:50\u001B[0m, in \u001B[0;36mStream._iter_events\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_iter_events\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[ServerSentEvent]:\n\u001B[0;32m---> 50\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoder\u001B[38;5;241m.\u001B[39miter_bytes(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39miter_bytes())\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:280\u001B[0m, in \u001B[0;36mSSEDecoder.iter_bytes\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21miter_bytes\u001B[39m(\u001B[38;5;28mself\u001B[39m, iterator: Iterator[\u001B[38;5;28mbytes\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[ServerSentEvent]:\n\u001B[1;32m    279\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001B[39;00m\n\u001B[0;32m--> 280\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_chunks(iterator):\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;66;03m# Split before decoding so splitlines() only uses \\r and \\n\u001B[39;00m\n\u001B[1;32m    282\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m raw_line \u001B[38;5;129;01min\u001B[39;00m chunk\u001B[38;5;241m.\u001B[39msplitlines():\n\u001B[1;32m    283\u001B[0m             line \u001B[38;5;241m=\u001B[39m raw_line\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:291\u001B[0m, in \u001B[0;36mSSEDecoder._iter_chunks\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001B[39;00m\n\u001B[1;32m    290\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 291\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m iterator:\n\u001B[1;32m    292\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m chunk\u001B[38;5;241m.\u001B[39msplitlines(keepends\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    293\u001B[0m         data \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m line\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpx/_models.py:831\u001B[0m, in \u001B[0;36mResponse.iter_bytes\u001B[0;34m(self, chunk_size)\u001B[0m\n\u001B[1;32m    829\u001B[0m chunker \u001B[38;5;241m=\u001B[39m ByteChunker(chunk_size\u001B[38;5;241m=\u001B[39mchunk_size)\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request):\n\u001B[0;32m--> 831\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m raw_bytes \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_raw():\n\u001B[1;32m    832\u001B[0m         decoded \u001B[38;5;241m=\u001B[39m decoder\u001B[38;5;241m.\u001B[39mdecode(raw_bytes)\n\u001B[1;32m    833\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunker\u001B[38;5;241m.\u001B[39mdecode(decoded):\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpx/_models.py:885\u001B[0m, in \u001B[0;36mResponse.iter_raw\u001B[0;34m(self, chunk_size)\u001B[0m\n\u001B[1;32m    882\u001B[0m chunker \u001B[38;5;241m=\u001B[39m ByteChunker(chunk_size\u001B[38;5;241m=\u001B[39mchunk_size)\n\u001B[1;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request):\n\u001B[0;32m--> 885\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m raw_stream_bytes \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream:\n\u001B[1;32m    886\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_bytes_downloaded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(raw_stream_bytes)\n\u001B[1;32m    887\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunker\u001B[38;5;241m.\u001B[39mdecode(raw_stream_bytes):\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpx/_client.py:127\u001B[0m, in \u001B[0;36mBoundSyncStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m typing\u001B[38;5;241m.\u001B[39mIterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream:\n\u001B[1;32m    128\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpx/_transports/default.py:116\u001B[0m, in \u001B[0;36mResponseStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m typing\u001B[38;5;241m.\u001B[39mIterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m part \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_httpcore_stream:\n\u001B[1;32m    117\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m part\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:367\u001B[0m, in \u001B[0;36mPoolByteStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    366\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:363\u001B[0m, in \u001B[0;36mPoolByteStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 363\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m part \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream:\n\u001B[1;32m    364\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m part\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:349\u001B[0m, in \u001B[0;36mHTTP11ConnectionByteStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ShieldCancellation():\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m--> 349\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:341\u001B[0m, in \u001B[0;36mHTTP11ConnectionByteStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_body\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request, kwargs):\n\u001B[0;32m--> 341\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39m_receive_response_body(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    342\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    344\u001B[0m     \u001B[38;5;66;03m# If we get an exception while streaming the response,\u001B[39;00m\n\u001B[1;32m    345\u001B[0m     \u001B[38;5;66;03m# we want to close the response (and possibly the connection)\u001B[39;00m\n\u001B[1;32m    346\u001B[0m     \u001B[38;5;66;03m# before raising that exception.\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:210\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_response_body\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    207\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeouts\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 210\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mData):\n\u001B[1;32m    212\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mbytes\u001B[39m(event\u001B[38;5;241m.\u001B[39mdata)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:224\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_event\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    221\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[0;32m--> 224\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_network_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mtheir_state \u001B[38;5;241m==\u001B[39m h11\u001B[38;5;241m.\u001B[39mSEND_RESPONSE:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_backends/sync.py:126\u001B[0m, in \u001B[0;36mSyncStream.read\u001B[0;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001B[0m, in \u001B[0;36mSSLSocket.recv\u001B[0;34m(self, buflen, flags)\u001B[0m\n\u001B[1;32m   1222\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1223\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1224\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1225\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1226\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuflen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1228\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv(buflen, flags)\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1099\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1101\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1102\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SSLError \u001B[38;5;28;01mas\u001B[39;00m x:\n\u001B[1;32m   1103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m SSL_ERROR_EOF \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuppress_ragged_eofs:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"Tell me all the ASC required for the basic requirements of Item 18 of Form 20-F\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T09:19:08.064364Z",
     "start_time": "2024-10-01T09:18:45.451349Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"UNSTRUCTURED_API_KEY\"] = \"CgZ4DwANPQjwZKgDMGvO0mEh8nT7pB\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T13:36:31.123832Z",
     "start_time": "2024-10-01T13:36:31.122082Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-unstructured in ./venv/lib/python3.9/site-packages (0.1.5)\r\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in ./venv/lib/python3.9/site-packages (from langchain-unstructured) (0.3.7)\r\n",
      "Requirement already satisfied: unstructured-client<0.26.0,>=0.25.0 in ./venv/lib/python3.9/site-packages (from langchain-unstructured) (0.25.9)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./venv/lib/python3.9/site-packages (from langchain-core<0.4,>=0.3->langchain-unstructured) (8.5.0)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.9/site-packages (from langchain-core<0.4,>=0.3->langchain-unstructured) (24.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.9/site-packages (from langchain-core<0.4,>=0.3->langchain-unstructured) (1.33)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.9/site-packages (from langchain-core<0.4,>=0.3->langchain-unstructured) (4.12.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in ./venv/lib/python3.9/site-packages (from langchain-core<0.4,>=0.3->langchain-unstructured) (2.9.2)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./venv/lib/python3.9/site-packages (from langchain-core<0.4,>=0.3->langchain-unstructured) (0.1.129)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.9/site-packages (from langchain-core<0.4,>=0.3->langchain-unstructured) (6.0.2)\r\n",
      "Requirement already satisfied: cryptography>=3.1 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (43.0.1)\r\n",
      "Requirement already satisfied: marshmallow>=3.19.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (3.22.0)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (0.27.2)\r\n",
      "Requirement already satisfied: dataclasses-json>=0.6.4 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (0.6.7)\r\n",
      "Requirement already satisfied: idna>=3.4 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (3.10)\r\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.0.6)\r\n",
      "Requirement already satisfied: deepdiff>=6.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (8.0.1)\r\n",
      "Requirement already satisfied: certifi>=2023.7.22 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (2024.8.30)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (2.32.3)\r\n",
      "Requirement already satisfied: pypdf>=4.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (5.0.1)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.0.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.18 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.26.20)\r\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.0.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (0.9.0)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.6.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (2.9.0.post0)\r\n",
      "Requirement already satisfied: charset-normalizer>=3.2.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (3.3.2)\r\n",
      "Requirement already satisfied: six>=1.16.0 in ./venv/lib/python3.9/site-packages (from unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.16.0)\r\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib/python3.9/site-packages (from cryptography>=3.1->unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.17.1)\r\n",
      "Requirement already satisfied: orderly-set==5.2.2 in ./venv/lib/python3.9/site-packages (from deepdiff>=6.0->unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (5.2.2)\r\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.3.1)\r\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (4.6.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-unstructured) (3.0.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-unstructured) (3.10.7)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-unstructured) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-unstructured) (2.23.4)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (2.22)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->unstructured-client<0.26.0,>=0.25.0->langchain-unstructured) (1.2.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Install package, compatible with API partitioning\n",
    "!pip install langchain-unstructured"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T13:37:18.847484Z",
     "start_time": "2024-10-01T13:37:15.449822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured-client in ./venv/lib/python3.9/site-packages (0.25.9)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (1.0.0)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (0.27.2)\r\n",
      "Requirement already satisfied: idna>=3.4 in ./venv/lib/python3.9/site-packages (from unstructured-client) (3.10)\r\n",
      "Requirement already satisfied: deepdiff>=6.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (8.0.1)\r\n",
      "Requirement already satisfied: pypdf>=4.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (5.0.1)\r\n",
      "Requirement already satisfied: six>=1.16.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (1.16.0)\r\n",
      "Requirement already satisfied: cryptography>=3.1 in ./venv/lib/python3.9/site-packages (from unstructured-client) (43.0.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (1.0.0)\r\n",
      "Requirement already satisfied: marshmallow>=3.19.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (3.22.0)\r\n",
      "Requirement already satisfied: charset-normalizer>=3.2.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (3.3.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7.1 in ./venv/lib/python3.9/site-packages (from unstructured-client) (4.12.2)\r\n",
      "Requirement already satisfied: dataclasses-json>=0.6.4 in ./venv/lib/python3.9/site-packages (from unstructured-client) (0.6.7)\r\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (0.9.0)\r\n",
      "Requirement already satisfied: certifi>=2023.7.22 in ./venv/lib/python3.9/site-packages (from unstructured-client) (2024.8.30)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (2.32.3)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./venv/lib/python3.9/site-packages (from unstructured-client) (1.6.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.18 in ./venv/lib/python3.9/site-packages (from unstructured-client) (1.26.20)\r\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in ./venv/lib/python3.9/site-packages (from unstructured-client) (1.0.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from unstructured-client) (2.9.0.post0)\r\n",
      "Requirement already satisfied: packaging>=23.1 in ./venv/lib/python3.9/site-packages (from unstructured-client) (24.1)\r\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib/python3.9/site-packages (from cryptography>=3.1->unstructured-client) (1.17.1)\r\n",
      "Requirement already satisfied: orderly-set==5.2.2 in ./venv/lib/python3.9/site-packages (from deepdiff>=6.0->unstructured-client) (5.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client) (1.3.1)\r\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client) (4.6.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client) (0.14.0)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client) (2.22)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->unstructured-client) (1.2.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured-client"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T13:37:49.586481Z",
     "start_time": "2024-10-01T13:37:46.285365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in ./venv/lib/python3.9/site-packages (0.15.13)\r\n",
      "Requirement already satisfied: python-magic in ./venv/lib/python3.9/site-packages (0.4.27)\r\n",
      "Requirement already satisfied: unstructured-client in ./venv/lib/python3.9/site-packages (from unstructured) (0.25.9)\r\n",
      "Requirement already satisfied: chardet in ./venv/lib/python3.9/site-packages (from unstructured) (5.2.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.9/site-packages (from unstructured) (4.12.3)\r\n",
      "Requirement already satisfied: tabulate in ./venv/lib/python3.9/site-packages (from unstructured) (0.9.0)\r\n",
      "Requirement already satisfied: langdetect in ./venv/lib/python3.9/site-packages (from unstructured) (1.0.9)\r\n",
      "Requirement already satisfied: python-oxmsg in ./venv/lib/python3.9/site-packages (from unstructured) (0.0.1)\r\n",
      "Requirement already satisfied: rapidfuzz in ./venv/lib/python3.9/site-packages (from unstructured) (3.10.0)\r\n",
      "Requirement already satisfied: backoff in ./venv/lib/python3.9/site-packages (from unstructured) (2.2.1)\r\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.9/site-packages (from unstructured) (1.16.0)\r\n",
      "Requirement already satisfied: python-iso639 in ./venv/lib/python3.9/site-packages (from unstructured) (2024.4.27)\r\n",
      "Requirement already satisfied: numpy<2 in ./venv/lib/python3.9/site-packages (from unstructured) (1.26.4)\r\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.9/site-packages (from unstructured) (3.9.1)\r\n",
      "Requirement already satisfied: filetype in ./venv/lib/python3.9/site-packages (from unstructured) (1.2.0)\r\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.9/site-packages (from unstructured) (6.0.0)\r\n",
      "Requirement already satisfied: lxml in ./venv/lib/python3.9/site-packages (from unstructured) (5.3.0)\r\n",
      "Requirement already satisfied: emoji in ./venv/lib/python3.9/site-packages (from unstructured) (2.13.2)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from unstructured) (4.66.5)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from unstructured) (2.32.3)\r\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.9/site-packages (from unstructured) (4.12.2)\r\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.9/site-packages (from unstructured) (0.6.7)\r\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in ./venv/lib/python3.9/site-packages (from unstructured) (0.3.13)\r\n",
      "Requirement already satisfied: pdf2image in ./venv/lib/python3.9/site-packages (from unstructured) (1.17.0)\r\n",
      "Requirement already satisfied: google-cloud-vision in ./venv/lib/python3.9/site-packages (from unstructured) (3.7.4)\r\n",
      "Requirement already satisfied: pdfminer.six in ./venv/lib/python3.9/site-packages (from unstructured) (20231228)\r\n",
      "Requirement already satisfied: pypdf in ./venv/lib/python3.9/site-packages (from unstructured) (5.0.1)\r\n",
      "Requirement already satisfied: effdet in ./venv/lib/python3.9/site-packages (from unstructured) (0.4.1)\r\n",
      "Requirement already satisfied: pi-heif in ./venv/lib/python3.9/site-packages (from unstructured) (0.18.0)\r\n",
      "Requirement already satisfied: unstructured-inference==0.7.36 in ./venv/lib/python3.9/site-packages (from unstructured) (0.7.36)\r\n",
      "Requirement already satisfied: pikepdf in ./venv/lib/python3.9/site-packages (from unstructured) (9.3.0)\r\n",
      "Requirement already satisfied: onnx in ./venv/lib/python3.9/site-packages (from unstructured) (1.16.2)\r\n",
      "Requirement already satisfied: python-multipart in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured) (0.0.12)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured) (2.4.1)\r\n",
      "Requirement already satisfied: transformers>=4.25.1 in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured) (4.45.1)\r\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured) (4.10.0.84)\r\n",
      "Requirement already satisfied: timm in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured) (1.0.9)\r\n",
      "Requirement already satisfied: layoutparser in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured) (0.3.4)\r\n",
      "Requirement already satisfied: huggingface-hub in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured) (0.25.1)\r\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured) (1.19.2)\r\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured) (3.9.2)\r\n",
      "Requirement already satisfied: Pillow>=8.0.0 in ./venv/lib/python3.9/site-packages (from unstructured.pytesseract>=0.3.12->unstructured) (10.4.0)\r\n",
      "Requirement already satisfied: packaging>=21.3 in ./venv/lib/python3.9/site-packages (from unstructured.pytesseract>=0.3.12->unstructured) (24.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.9/site-packages (from beautifulsoup4->unstructured) (2.6)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.9/site-packages (from dataclasses-json->unstructured) (0.9.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.9/site-packages (from dataclasses-json->unstructured) (3.22.0)\r\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in ./venv/lib/python3.9/site-packages (from effdet->unstructured) (2.0.8)\r\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.9/site-packages (from effdet->unstructured) (0.19.1)\r\n",
      "Requirement already satisfied: omegaconf>=2.0 in ./venv/lib/python3.9/site-packages (from effdet->unstructured) (2.3.0)\r\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./venv/lib/python3.9/site-packages (from google-cloud-vision->unstructured) (1.24.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in ./venv/lib/python3.9/site-packages (from google-cloud-vision->unstructured) (5.28.2)\r\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in ./venv/lib/python3.9/site-packages (from google-cloud-vision->unstructured) (2.20.0)\r\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in ./venv/lib/python3.9/site-packages (from google-cloud-vision->unstructured) (2.35.0)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from langdetect->unstructured) (1.16.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.9/site-packages (from nltk->unstructured) (2024.9.11)\r\n",
      "Requirement already satisfied: click in ./venv/lib/python3.9/site-packages (from nltk->unstructured) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.9/site-packages (from nltk->unstructured) (1.4.2)\r\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./venv/lib/python3.9/site-packages (from pdfminer.six->unstructured) (3.3.2)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./venv/lib/python3.9/site-packages (from pdfminer.six->unstructured) (43.0.1)\r\n",
      "Requirement already satisfied: Deprecated in ./venv/lib/python3.9/site-packages (from pikepdf->unstructured) (1.2.14)\r\n",
      "Requirement already satisfied: olefile in ./venv/lib/python3.9/site-packages (from python-oxmsg->unstructured) (0.47)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->unstructured) (2024.8.30)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->unstructured) (1.26.20)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->unstructured) (3.10)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (2.9.0.post0)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (1.0.0)\r\n",
      "Requirement already satisfied: deepdiff>=6.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (8.0.1)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (1.6.0)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (0.27.2)\r\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (1.0.6)\r\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured) (1.0.0)\r\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.17.1)\r\n",
      "Requirement already satisfied: orderly-set==5.2.2 in ./venv/lib/python3.9/site-packages (from deepdiff>=6.0->unstructured-client->unstructured) (5.2.2)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured) (1.65.0)\r\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in ./venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured) (1.66.2)\r\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in ./venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured) (1.66.2)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured) (5.5.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.9/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured) (4.9)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.9/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured) (0.4.1)\r\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\r\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.6.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in ./venv/lib/python3.9/site-packages (from omegaconf>=2.0->effdet->unstructured) (6.0.2)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./venv/lib/python3.9/site-packages (from omegaconf>=2.0->effdet->unstructured) (4.9.3)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured) (1.13.3)\r\n",
      "Requirement already satisfied: flatbuffers in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured) (24.3.25)\r\n",
      "Requirement already satisfied: coloredlogs in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured) (15.0.1)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured) (6.4.5)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured) (1.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured) (3.1.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured) (1.4.7)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured) (4.54.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured) (0.12.1)\r\n",
      "Requirement already satisfied: safetensors in ./venv/lib/python3.9/site-packages (from timm->unstructured-inference==0.7.36->unstructured) (0.4.5)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from torch->unstructured-inference==0.7.36->unstructured) (3.16.1)\r\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.9/site-packages (from torch->unstructured-inference==0.7.36->unstructured) (2024.9.0)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch->unstructured-inference==0.7.36->unstructured) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch->unstructured-inference==0.7.36->unstructured) (3.1.4)\r\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./venv/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured) (0.20.0)\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured) (2.2.3)\r\n",
      "Requirement already satisfied: pdfplumber in ./venv/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured) (0.11.4)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured) (1.13.1)\r\n",
      "Requirement already satisfied: iopath in ./venv/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured) (0.1.10)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.22)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->unstructured-inference==0.7.36->unstructured) (3.20.2)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured) (0.6.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured) (10.0)\r\n",
      "Requirement already satisfied: portalocker in ./venv/lib/python3.9/site-packages (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured) (2.10.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch->unstructured-inference==0.7.36->unstructured) (2.1.5)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.9/site-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured) (2024.2)\r\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in ./venv/lib/python3.9/site-packages (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured) (4.30.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.9/site-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured \"unstructured[pdf]\" python-magic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T13:37:54.449516Z",
     "start_time": "2024-10-01T13:37:50.771337Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[pdf] in ./venv/lib/python3.9/site-packages (0.15.13)\r\n",
      "Requirement already satisfied: python-magic in ./venv/lib/python3.9/site-packages (0.4.27)\r\n",
      "Requirement already satisfied: backoff in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (2.2.1)\r\n",
      "Requirement already satisfied: python-iso639 in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (2024.4.27)\r\n",
      "Requirement already satisfied: langdetect in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (1.0.9)\r\n",
      "Requirement already satisfied: rapidfuzz in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (3.10.0)\r\n",
      "Requirement already satisfied: filetype in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (1.2.0)\r\n",
      "Requirement already satisfied: emoji in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (2.13.2)\r\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (4.12.2)\r\n",
      "Requirement already satisfied: chardet in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (5.2.0)\r\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (0.6.7)\r\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (3.9.1)\r\n",
      "Requirement already satisfied: tabulate in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (0.9.0)\r\n",
      "Requirement already satisfied: lxml in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (5.3.0)\r\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (1.16.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (4.12.3)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (2.32.3)\r\n",
      "Requirement already satisfied: numpy<2 in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (1.26.4)\r\n",
      "Requirement already satisfied: unstructured-client in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (0.25.9)\r\n",
      "Requirement already satisfied: python-oxmsg in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (0.0.1)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (4.66.5)\r\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (6.0.0)\r\n",
      "Requirement already satisfied: pdfminer.six in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (20231228)\r\n",
      "Requirement already satisfied: google-cloud-vision in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (3.7.4)\r\n",
      "Requirement already satisfied: onnx in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (1.16.2)\r\n",
      "Requirement already satisfied: effdet in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (0.4.1)\r\n",
      "Requirement already satisfied: pypdf in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (5.0.1)\r\n",
      "Requirement already satisfied: pikepdf in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (9.3.0)\r\n",
      "Requirement already satisfied: pdf2image in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (1.17.0)\r\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (0.3.13)\r\n",
      "Requirement already satisfied: pi-heif in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (0.18.0)\r\n",
      "Requirement already satisfied: unstructured-inference==0.7.36 in ./venv/lib/python3.9/site-packages (from unstructured[pdf]) (0.7.36)\r\n",
      "Requirement already satisfied: timm in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (1.0.9)\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (2.4.1)\r\n",
      "Requirement already satisfied: python-multipart in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (0.0.12)\r\n",
      "Requirement already satisfied: layoutparser in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (0.3.4)\r\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (1.19.2)\r\n",
      "Requirement already satisfied: transformers>=4.25.1 in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (4.45.1)\r\n",
      "Requirement already satisfied: huggingface-hub in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (0.25.1)\r\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (3.9.2)\r\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in ./venv/lib/python3.9/site-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (4.10.0.84)\r\n",
      "Requirement already satisfied: Pillow>=8.0.0 in ./venv/lib/python3.9/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (10.4.0)\r\n",
      "Requirement already satisfied: packaging>=21.3 in ./venv/lib/python3.9/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (24.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.9/site-packages (from beautifulsoup4->unstructured[pdf]) (2.6)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.9/site-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.9/site-packages (from dataclasses-json->unstructured[pdf]) (3.22.0)\r\n",
      "Requirement already satisfied: omegaconf>=2.0 in ./venv/lib/python3.9/site-packages (from effdet->unstructured[pdf]) (2.3.0)\r\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.9/site-packages (from effdet->unstructured[pdf]) (0.19.1)\r\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in ./venv/lib/python3.9/site-packages (from effdet->unstructured[pdf]) (2.0.8)\r\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./venv/lib/python3.9/site-packages (from google-cloud-vision->unstructured[pdf]) (1.24.0)\r\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in ./venv/lib/python3.9/site-packages (from google-cloud-vision->unstructured[pdf]) (2.20.0)\r\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in ./venv/lib/python3.9/site-packages (from google-cloud-vision->unstructured[pdf]) (2.35.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in ./venv/lib/python3.9/site-packages (from google-cloud-vision->unstructured[pdf]) (5.28.2)\r\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from langdetect->unstructured[pdf]) (1.16.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.9/site-packages (from nltk->unstructured[pdf]) (2024.9.11)\r\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.9/site-packages (from nltk->unstructured[pdf]) (1.4.2)\r\n",
      "Requirement already satisfied: click in ./venv/lib/python3.9/site-packages (from nltk->unstructured[pdf]) (8.1.7)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./venv/lib/python3.9/site-packages (from pdfminer.six->unstructured[pdf]) (43.0.1)\r\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./venv/lib/python3.9/site-packages (from pdfminer.six->unstructured[pdf]) (3.3.2)\r\n",
      "Requirement already satisfied: Deprecated in ./venv/lib/python3.9/site-packages (from pikepdf->unstructured[pdf]) (1.2.14)\r\n",
      "Requirement already satisfied: olefile in ./venv/lib/python3.9/site-packages (from python-oxmsg->unstructured[pdf]) (0.47)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->unstructured[pdf]) (2024.8.30)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->unstructured[pdf]) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->unstructured[pdf]) (1.26.20)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (2.9.0.post0)\r\n",
      "Requirement already satisfied: deepdiff>=6.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (8.0.1)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (1.6.0)\r\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (1.0.6)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (0.27.2)\r\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./venv/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\r\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.17.1)\r\n",
      "Requirement already satisfied: orderly-set==5.2.2 in ./venv/lib/python3.9/site-packages (from deepdiff>=6.0->unstructured-client->unstructured[pdf]) (5.2.2)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.65.0)\r\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in ./venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.66.2)\r\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in ./venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.66.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.9/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.5.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.9/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.0.5)\r\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (4.6.0)\r\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (0.14.0)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./venv/lib/python3.9/site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (4.9.3)\r\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in ./venv/lib/python3.9/site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.2)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (1.13.3)\r\n",
      "Requirement already satisfied: coloredlogs in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (15.0.1)\r\n",
      "Requirement already satisfied: flatbuffers in ./venv/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (24.3.25)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (6.4.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (0.12.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (3.1.4)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (4.54.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (1.4.7)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (1.3.0)\r\n",
      "Requirement already satisfied: safetensors in ./venv/lib/python3.9/site-packages (from timm->unstructured-inference==0.7.36->unstructured[pdf]) (0.4.5)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (3.1.4)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (3.2.1)\r\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.9/site-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (2024.9.0)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (3.16.1)\r\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./venv/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured[pdf]) (0.20.0)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (1.13.1)\r\n",
      "Requirement already satisfied: pdfplumber in ./venv/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (0.11.4)\r\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2.2.3)\r\n",
      "Requirement already satisfied: iopath in ./venv/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (0.1.10)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.22)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (3.20.2)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.2.2)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./venv/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (10.0)\r\n",
      "Requirement already satisfied: portalocker in ./venv/lib/python3.9/site-packages (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2.10.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch->unstructured-inference==0.7.36->unstructured[pdf]) (2.1.5)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.9/site-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2024.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2024.2)\r\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in ./venv/lib/python3.9/site-packages (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (4.30.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.9/site-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unstructured[pdf]\" python-magic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T13:37:58.911322Z",
     "start_time": "2024-10-01T13:37:55.369282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "file_paths = [\n",
    "    \"Mahindra_dg.pdf\",\n",
    "]\n",
    "\n",
    "\n",
    "loader = UnstructuredLoader(file_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:07:50.626017Z",
     "start_time": "2024-10-01T14:07:50.620377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "docs = loader.load()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:07:51.253419Z",
     "start_time": "2024-10-01T14:07:51.161121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected metadata value to be a str, int, float or bool, got {'points': ((447.341, 24.716999999999985), (447.341, 37.65999999999997), (541.5514, 37.65999999999997), (541.5514, 24.716999999999985)), 'system': 'PixelSpace', 'layout_width': 594, 'layout_height': 774} which is a dict\n\nTry filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_chroma/vectorstores.py:530\u001B[0m, in \u001B[0;36mChroma.add_texts\u001B[0;34m(self, texts, metadatas, ids, **kwargs)\u001B[0m\n\u001B[1;32m    529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 530\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_collection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupsert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m    532\u001B[0m \u001B[43m        \u001B[49m\u001B[43membeddings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membeddings_with_metadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m    533\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts_with_metadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    534\u001B[0m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mids_with_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    535\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/chromadb/api/models/Collection.py:298\u001B[0m, in \u001B[0;36mCollection.upsert\u001B[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001B[39;00m\n\u001B[1;32m    282\u001B[0m \n\u001B[1;32m    283\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    None\u001B[39;00m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    292\u001B[0m (\n\u001B[1;32m    293\u001B[0m     ids,\n\u001B[1;32m    294\u001B[0m     embeddings,\n\u001B[1;32m    295\u001B[0m     metadatas,\n\u001B[1;32m    296\u001B[0m     documents,\n\u001B[1;32m    297\u001B[0m     uris,\n\u001B[0;32m--> 298\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_and_prepare_upsert_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muris\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39m_upsert(\n\u001B[1;32m    303\u001B[0m     collection_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid,\n\u001B[1;32m    304\u001B[0m     ids\u001B[38;5;241m=\u001B[39mids,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    308\u001B[0m     uris\u001B[38;5;241m=\u001B[39muris,\n\u001B[1;32m    309\u001B[0m )\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/chromadb/api/models/CollectionCommon.py:540\u001B[0m, in \u001B[0;36mCollectionCommon._validate_and_prepare_upsert_request\u001B[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001B[0m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_and_prepare_upsert_request\u001B[39m(\n\u001B[1;32m    514\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    515\u001B[0m     ids: OneOrMany[ID],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    531\u001B[0m     Optional[URIs],\n\u001B[1;32m    532\u001B[0m ]:\n\u001B[1;32m    533\u001B[0m     (\n\u001B[1;32m    534\u001B[0m         ids,\n\u001B[1;32m    535\u001B[0m         embeddings,\n\u001B[1;32m    536\u001B[0m         metadatas,\n\u001B[1;32m    537\u001B[0m         documents,\n\u001B[1;32m    538\u001B[0m         images,\n\u001B[1;32m    539\u001B[0m         uris,\n\u001B[0;32m--> 540\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_embedding_set\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muris\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m embeddings \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/chromadb/api/models/CollectionCommon.py:183\u001B[0m, in \u001B[0;36mCollectionCommon._validate_embedding_set\u001B[0;34m(self, ids, embeddings, metadatas, documents, images, uris, require_embeddings_or_data)\u001B[0m\n\u001B[1;32m    175\u001B[0m valid_embeddings \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    176\u001B[0m     validate_embeddings(\n\u001B[1;32m    177\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_normalize_embeddings(maybe_cast_one_to_many_embedding(embeddings))\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    181\u001B[0m )\n\u001B[1;32m    182\u001B[0m valid_metadatas \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 183\u001B[0m     \u001B[43mvalidate_metadatas\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_cast_one_to_many_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m metadatas \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m )\n\u001B[1;32m    187\u001B[0m valid_documents \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    188\u001B[0m     maybe_cast_one_to_many_document(documents)\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m documents \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    191\u001B[0m )\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/chromadb/api/types.py:361\u001B[0m, in \u001B[0;36mvalidate_metadatas\u001B[0;34m(metadatas)\u001B[0m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m metadata \u001B[38;5;129;01min\u001B[39;00m metadatas:\n\u001B[0;32m--> 361\u001B[0m     \u001B[43mvalidate_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m metadatas\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/chromadb/api/types.py:327\u001B[0m, in \u001B[0;36mvalidate_metadata\u001B[0;34m(metadata)\u001B[0m\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m)):\n\u001B[0;32m--> 327\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    328\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected metadata value to be a str, int, float or bool, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m which is a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    329\u001B[0m         )\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m metadata\n",
      "\u001B[0;31mValueError\u001B[0m: Expected metadata value to be a str, int, float or bool, got {'points': ((447.341, 24.716999999999985), (447.341, 37.65999999999997), (541.5514, 37.65999999999997), (541.5514, 24.716999999999985)), 'system': 'PixelSpace', 'layout_width': 594, 'layout_height': 774} which is a dict",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m vectorstore \u001B[38;5;241m=\u001B[39m \u001B[43mChroma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mOpenAIEmbeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_chroma/vectorstores.py:1128\u001B[0m, in \u001B[0;36mChroma.from_documents\u001B[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m texts \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mpage_content \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[1;32m   1127\u001B[0m metadatas \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[0;32m-> 1128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1130\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1132\u001B[0m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1133\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1134\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpersist_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_settings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_settings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1136\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1137\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1138\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1139\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_chroma/vectorstores.py:1089\u001B[0m, in \u001B[0;36mChroma.from_texts\u001B[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[1;32m   1083\u001B[0m         chroma_collection\u001B[38;5;241m.\u001B[39madd_texts(\n\u001B[1;32m   1084\u001B[0m             texts\u001B[38;5;241m=\u001B[39mbatch[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m batch[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m [],\n\u001B[1;32m   1085\u001B[0m             metadatas\u001B[38;5;241m=\u001B[39mbatch[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m batch[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   1086\u001B[0m             ids\u001B[38;5;241m=\u001B[39mbatch[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m   1087\u001B[0m         )\n\u001B[1;32m   1088\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1089\u001B[0m     \u001B[43mchroma_collection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1090\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m chroma_collection\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_chroma/vectorstores.py:542\u001B[0m, in \u001B[0;36mChroma.add_texts\u001B[0;34m(self, texts, metadatas, ids, **kwargs)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected metadata value to be\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n\u001B[1;32m    538\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    539\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTry filtering complex metadata from the document using \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    540\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlangchain_community.vectorstores.utils.filter_complex_metadata.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    541\u001B[0m     )\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(e\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m msg)\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "\u001B[0;31mValueError\u001B[0m: Expected metadata value to be a str, int, float or bool, got {'points': ((447.341, 24.716999999999985), (447.341, 37.65999999999997), (541.5514, 37.65999999999997), (541.5514, 24.716999999999985)), 'system': 'PixelSpace', 'layout_width': 594, 'layout_height': 774} which is a dict\n\nTry filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata."
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=OpenAIEmbeddings())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:15:04.939350Z",
     "start_time": "2024-10-01T14:15:02.724889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "vectorstore = Chroma.from_documents(filter_complex_metadata(docs), embedding=OpenAIEmbeddings())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:20:39.928451Z",
     "start_time": "2024-10-01T14:20:37.842614Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sales volume in the Auto segment increased by 11.7%, reaching 780,475 vehicles in the current year, up from 698,456 vehicles the previous year."
     ]
    }
   ],
   "source": [
    "# \"Percentage Increase in Income from investment related to subsidiaries, associates, and joint ventures from F23 to F24\"\n",
    "for chunk in rag_chain.stream(\"Sales volume in Auto segment\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T14:23:09.628529Z",
     "start_time": "2024-10-01T14:23:07.793135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "import bs4\n",
    "from urllib.request import urlopen as request\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "url = 'https://www.voaux.com'\n",
    "\n",
    "# opening connection, grabbing the HTML from the page\n",
    "client = request(url)\n",
    "page_html = client.read()\n",
    "client.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T06:18:46.808649Z",
     "start_time": "2024-10-02T06:18:46.582937Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "b'<!DOCTYPE html>\\n<html lang=\"en\">\\n  <head>\\n    <!-- Google tag (gtag.js) -->\\n    <script async src=\"https://www.googletagmanager.com/gtag/js?id=G-BCDVT2DQBD\"></script>\\n    <script>\\n      window.dataLayer = window.dataLayer || [];\\n      function gtag(){dataLayer.push(arguments);}\\n      gtag(\\'js\\', new Date());\\n\\n      gtag(\\'config\\', \\'G-BCDVT2DQBD\\');\\n    </script>\\n\\n    <meta charset=\"utf-8\" />\\n<!--    <link rel=\"icon\" href=\"%PUBLIC_URL%/favicon.ico\" />-->\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\\n    <meta name=\"theme-color\" content=\"#000000\" />\\n    <meta property=\"og:description\" content=\"VoiceOvers made simple\"/>\\n    <meta property=\"og:image\" content=\"./assets/voaux-logo.png\">\\n    <link rel=\"apple-touch-icon\" href=\"%PUBLIC_URL%/logo192.png\" />\\n    <!--\\n      manifest.json provides metadata used when your web app is installed on a\\n      user\\'s mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/\\n    -->\\n    <link rel=\"manifest\" href=\"/manifest.json\" />\\n    <!--\\n      Notice the use of %PUBLIC_URL% in the tags above.\\n      It will be replaced with the URL of the `public` folder during the build.\\n      Only files inside the `public` folder can be referenced from the HTML.\\n\\n      Unlike \"/favicon.ico\" or \"favicon.ico\", \"%PUBLIC_URL%/favicon.ico\" will\\n      work correctly both with client-side routing and a non-root public URL.\\n      Learn how to configure a non-root public URL by running `npm run build`.\\n    -->\\n    <!-- Start Single Page Apps for GitHub Pages -->\\n    <script type=\"text/javascript\">\\n      // Single Page Apps for GitHub Pages\\n      // MIT License\\n      // https://github.com/rafgraph/spa-github-pages\\n      // This script checks to see if a redirect is present in the query string,\\n      // converts it back into the correct url and adds it to the\\n      // browser\\'s history using window.history.replaceState(...),\\n      // which won\\'t cause the browser to attempt to load the new url.\\n      // When the single page app is loaded further down in this file,\\n      // the correct url will be waiting in the browser\\'s history for\\n      // the single page app to route accordingly.\\n      (function(l) {\\n        console.log(\"website is \"+ l);\\n        if (l.search[1] === \\'/\\' ) {\\n          var decoded = l.search.slice(1).split(\\'&\\').map(function(s) {\\n            return s.replace(/~and~/g, \\'&\\')\\n          }).join(\\'?\\');\\n          window.history.replaceState(null, null,\\n                  l.pathname.slice(0, -1) + decoded + l.hash\\n          );\\n        }\\n      }(window.location))\\n    </script>\\n    <script defer src=\"/bundle.js\"></script>\\n    <title>Voaux</title>\\n  </head>\\n  <body>\\n    <noscript>You need to enable JavaScript to run this app.</noscript>\\n    <div id=\"root\"></div>\\n\\n    <!--\\n      This HTML file is a template.\\n      If you open it directly in the browser, you will see an empty page.\\n\\n      You can add webfonts, meta tags, or analytics to this file.\\n      The build step will place the bundled scripts into the <body> tag.\\n\\n      To begin the development, run `npm start` or `yarn start`.\\n      To create a production bundle, use `npm run build` or `yarn build`.\\n    -->\\n  </body>\\n</html>\\n'"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_html"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T06:18:51.072916Z",
     "start_time": "2024-10-02T06:18:51.066621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "page_soup = soup(page_html, 'html.parser')\n",
    "cells = page_soup.find_all(\"div\", attrs={\"class\": \"item-cell\"})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Extract elements from PDF\n",
    "def extract_pdf_elements(path):\n",
    "    \"\"\"\n",
    "    Extract images, tables, and chunk text from a PDF file.\n",
    "    path: File path, which is used to dump images (.jpg)\n",
    "    fname: File name\n",
    "    \"\"\"\n",
    "    return partition_pdf(\n",
    "        filename=path,\n",
    "        strategy='hi_res',\n",
    "        extract_images_in_pdf=False,\n",
    "        infer_table_structure=True,\n",
    "        hi_res_model_name='yolox',\n",
    "        # chunking_strategy=\"by_title\",\n",
    "        # max_characters=4000,\n",
    "        # new_after_n_chars=3800,\n",
    "        # combine_text_under_n_chars=2000,\n",
    "        image_output_dir_path=path,\n",
    "    )\n",
    "\n",
    "def categorize_elements(raw_pdf_elements):\n",
    "    \"\"\"\n",
    "    Categorize extracted elements from a PDF into tables and texts.\n",
    "    raw_pdf_elements: List of unstructured.documents.elements\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    texts = []\n",
    "    for element in raw_pdf_elements:\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            tables.append(str(element))\n",
    "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "            texts.append(str(element))\n",
    "    return texts, tables"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:30:58.558461Z",
     "start_time": "2024-10-03T07:30:58.551614Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Reading PDF for file: tata-motor-report.pdf ...\n"
     ]
    }
   ],
   "source": [
    "fname = \"tata-motor-report.pdf\"\n",
    "\n",
    "# Get elements\n",
    "raw_pdf_elements = extract_pdf_elements(fname)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:39:25.821759Z",
     "start_time": "2024-10-03T07:31:01.104177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "data": {
      "text/plain": "[<unstructured.documents.elements.Title at 0x2f17731f0>,\n <unstructured.documents.elements.Title at 0x2f1773670>,\n <unstructured.documents.elements.Title at 0x2f1773520>,\n <unstructured.documents.elements.NarrativeText at 0x33da6b910>,\n <unstructured.documents.elements.Title at 0x33da6bfd0>,\n <unstructured.documents.elements.NarrativeText at 0x33da6b5b0>,\n <unstructured.documents.elements.NarrativeText at 0x2ecc6b850>,\n <unstructured.documents.elements.NarrativeText at 0x2ecc6b9a0>,\n <unstructured.documents.elements.Title at 0x2f1773280>,\n <unstructured.documents.elements.Title at 0x2f1773460>,\n <unstructured.documents.elements.Title at 0x2f17730a0>,\n <unstructured.documents.elements.Title at 0x2f1773b20>,\n <unstructured.documents.elements.Text at 0x2f17735e0>,\n <unstructured.documents.elements.Title at 0x2f1773040>,\n <unstructured.documents.elements.Title at 0x35b82c910>,\n <unstructured.documents.elements.Title at 0x2f1773760>,\n <unstructured.documents.elements.Table at 0x35b82caf0>,\n <unstructured.documents.elements.Table at 0x35b81eeb0>,\n <unstructured.documents.elements.Text at 0x2f1773610>,\n <unstructured.documents.elements.Text at 0x2f17733a0>,\n <unstructured.documents.elements.Title at 0x2f1773df0>,\n <unstructured.documents.elements.Title at 0x2f1773100>,\n <unstructured.documents.elements.Text at 0x2f1773f10>,\n <unstructured.documents.elements.Text at 0x2f17734c0>,\n <unstructured.documents.elements.Title at 0x2f17732b0>,\n <unstructured.documents.elements.Text at 0x2f1773b80>,\n <unstructured.documents.elements.Text at 0x2f1773160>,\n <unstructured.documents.elements.Text at 0x3d20338b0>,\n <unstructured.documents.elements.Text at 0x3d2033280>,\n <unstructured.documents.elements.Text at 0x3d2033c70>,\n <unstructured.documents.elements.Title at 0x3d2033370>,\n <unstructured.documents.elements.Text at 0x3d2033310>,\n <unstructured.documents.elements.Text at 0x3d20333a0>,\n <unstructured.documents.elements.Text at 0x3d2033130>,\n <unstructured.documents.elements.Text at 0x3d2033eb0>,\n <unstructured.documents.elements.Text at 0x3d2033c40>,\n <unstructured.documents.elements.Title at 0x3d2033760>,\n <unstructured.documents.elements.Text at 0x3d2033b80>,\n <unstructured.documents.elements.Text at 0x3d2033e50>,\n <unstructured.documents.elements.Text at 0x3d2033b50>,\n <unstructured.documents.elements.Text at 0x3d20331f0>,\n <unstructured.documents.elements.Title at 0x3d20337c0>,\n <unstructured.documents.elements.Title at 0x2ebdbe820>,\n <unstructured.documents.elements.Title at 0x3d2033160>,\n <unstructured.documents.elements.Table at 0x2ebdbe9a0>,\n <unstructured.documents.elements.NarrativeText at 0x3d2033040>,\n <unstructured.documents.elements.NarrativeText at 0x2ebdbe040>,\n <unstructured.documents.elements.Title at 0x3d20334f0>,\n <unstructured.documents.elements.Title at 0x3089060a0>,\n <unstructured.documents.elements.Text at 0x308906280>,\n <unstructured.documents.elements.Title at 0x308906130>,\n <unstructured.documents.elements.NarrativeText at 0x2ece53f70>,\n <unstructured.documents.elements.Title at 0x308906490>,\n <unstructured.documents.elements.Title at 0x37bcb4fa0>,\n <unstructured.documents.elements.Title at 0x37bcb4fd0>,\n <unstructured.documents.elements.Text at 0x37bcb4c10>,\n <unstructured.documents.elements.Title at 0x37bcb4730>,\n <unstructured.documents.elements.NarrativeText at 0x2ece53b50>,\n <unstructured.documents.elements.Title at 0x37bcb4910>,\n <unstructured.documents.elements.Text at 0x37bcb4640>,\n <unstructured.documents.elements.Title at 0x37bcb49d0>,\n <unstructured.documents.elements.Text at 0x3dd7de850>,\n <unstructured.documents.elements.NarrativeText at 0x2ebdb84c0>,\n <unstructured.documents.elements.Text at 0x3dd7de880>,\n <unstructured.documents.elements.Text at 0x3dd7de730>,\n <unstructured.documents.elements.NarrativeText at 0x2ebdb8a30>,\n <unstructured.documents.elements.Title at 0x3dd7de7f0>,\n <unstructured.documents.elements.Title at 0x3dd7def70>,\n <unstructured.documents.elements.Title at 0x3dd7de760>,\n <unstructured.documents.elements.Title at 0x3dd7de2e0>,\n <unstructured.documents.elements.Image at 0x2ebdb8100>,\n <unstructured.documents.elements.Title at 0x2ece60160>,\n <unstructured.documents.elements.Table at 0x2ece60430>,\n <unstructured.documents.elements.Title at 0x39aa26760>,\n <unstructured.documents.elements.Text at 0x39aa263d0>,\n <unstructured.documents.elements.Title at 0x39aa26370>,\n <unstructured.documents.elements.Text at 0x3dd7eef70>,\n <unstructured.documents.elements.Text at 0x3dd7eec40>,\n <unstructured.documents.elements.Title at 0x3dd7ee970>,\n <unstructured.documents.elements.Text at 0x3dd7ee8b0>,\n <unstructured.documents.elements.Title at 0x3dd7ee370>,\n <unstructured.documents.elements.Text at 0x3dd7ee2e0>,\n <unstructured.documents.elements.Title at 0x3dd7ee850>,\n <unstructured.documents.elements.Text at 0x3dd7ee2b0>,\n <unstructured.documents.elements.NarrativeText at 0x3dd7ee6d0>,\n <unstructured.documents.elements.Text at 0x3dd7eef10>,\n <unstructured.documents.elements.Title at 0x3dd7ee790>,\n <unstructured.documents.elements.ListItem at 0x3dd7eeca0>,\n <unstructured.documents.elements.Title at 0x3dd7eeee0>,\n <unstructured.documents.elements.Text at 0x3dd7ee460>,\n <unstructured.documents.elements.Title at 0x39aa34e50>,\n <unstructured.documents.elements.Title at 0x39aa340d0>,\n <unstructured.documents.elements.Text at 0x39aa34700>,\n <unstructured.documents.elements.Title at 0x39aa34490>,\n <unstructured.documents.elements.ListItem at 0x39aa349a0>,\n <unstructured.documents.elements.Text at 0x39aa34910>,\n <unstructured.documents.elements.ListItem at 0x39aa34b20>,\n <unstructured.documents.elements.ListItem at 0x39aa34d90>,\n <unstructured.documents.elements.ListItem at 0x39aa34610>,\n <unstructured.documents.elements.Text at 0x39aa34a00>]"
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pdf_elements[300:400]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:50:45.764443Z",
     "start_time": "2024-10-03T07:50:45.760578Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [
    {
     "data": {
      "text/plain": "'Particulars I. ASSETS (1) NON-CURRENT ASSETS (a) Property, plant and equipment (b) Capital work-in-progress (c) Right of use assets (d) Other intangible assets (e) Intangible assets under development (f) Financial assets: (i) Investments in subsidiaries, joint ventures and associates (ii) Other investments (iii) Loans (iv) Other financial assets (g) Deferred tax assets (net) (h) Non-current tax assets (net) (i) Other non-current assets (2) CURRENT ASSETS (a) Inventories (b) Financial assets: (i) Investments (ii) Trade receivables (iii) Cash and cash equivalents (iv) Bank balances other than (iii) above (v) Loans (vi) Other financial assets (c) Current tax assets (net) (d) Other current assets (3) Assets classified as held-for-sale TOTAL ASSETS II. EQUITY AND LIABILITIES EQUITY (a) Equity share capital (b) Other equity LIABILITIES (1) NON-CURRENT LIABILITIES (a) Financial liabilities: (i) Borrowings (ii) Lease liabilities (iii) Other financial liabilities (b) Provisions (c) Deferred tax liabilities (net) (d) Other non-current liabilities (2) CURRENT LIABILITIES (a) Financial liabilities: (i) Borrowings (ii) Lease liabilities (iii) Trade payables (a) Total outstanding dues of micro and small enterprises (b) Total outstanding dues of creditors other than micro and small enterprises (c) Acceptances (iv) Other financial liabilities (b) Provisions (c) Current tax liabilities (net) (d) Other current liabilities TOTAL EQUITY AND LIABILITIES Notes 3 (b) 3 (d) 4 (b) 5 (b) 5 (c) 6 7 9 11 28 13 15 (b) 8 16 18 (b) 19 10 12 14 3 (c) 20 22 25 27 (b) 28 29 23 24 26 27 (c) 30 As at As at March 31, 2024 March 31, 2023 11,563.76 11,707.87 645.03 575.65 426.50 421.27 2,353.79 2,413.18 588.92 509.30 28,729.45 27,976.80 1,586.12 1,204.82 101.89 114.40 1,830.34 2,405.23 1,558.65 1,477.26 1,008.32 868.22 483.30 596.82 50,876.07 50,270.82 3,470.38 3,027.90 1,993.50 3,142.96 2,765.16 2,307.72 3,344.89 1,121.43 1,806.07 293.22 132.19 40.44 547.50 347.10 12.00 - 1,099.37 1,219.18 15,171.06 11,499.95 36.61 - 66,083.74 61,770.77 766.50 766.02 29,376.55 21,703.83 30,143.05 22,469.85 5,235.67 10,445.70 296.28 305.26 252.53 414.44 1,936.92 1,588.75 49.78 51.16 843.35 692.08 8,614.53 13,497.39 8,535.37 8,426.74 123.32 100.99 189.85 114.67 8,636.61 7,047.93 4,508.01 5,839.39 1,146.25 1,300.18 1,133.92 408.89 73.61 53.66 2,979.22 2,511.08 27,326.16 25,803.53 66,083.74 61,770.77'"
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_pdf_elements[316]\n",
    "str(raw_pdf_elements[316])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:55:49.706573Z",
     "start_time": "2024-10-03T07:55:49.698244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [],
   "source": [
    "# Get text, tables\n",
    "texts, tables = categorize_elements(raw_pdf_elements)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:40:30.937174Z",
     "start_time": "2024-10-03T07:40:30.926585Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "data": {
      "text/plain": "'Financial liabilities Derivatives other than in hedging relationship (at fair value) Derivatives in hedging relationship at fair value through profit or loss Other financial liabilities at amortised cost Total carrying value (a) Long-term borrowings (including Current maturities of long-term borrowings) - - 7,087.20 7,087.20 (b) Lease liabilities - - 419.60 419.60 (c) Short-term borrowings - - 6,683.84 6,683.84 (d) Trade payables - - 8,826.46 8,826.46 (e) Acceptances - - 4,508.01 4,508.01 (f) Other financial liabilities 75.95 1.57 1,321.26 1,398.78 Total 75.95 1.57 28,846.37 28,923.89 Total fair value 7,130.70 419.60 6,683.84 8,826.46 4,508.01 1,398.78 28,967.39'"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[121]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:40:37.860591Z",
     "start_time": "2024-10-03T07:40:37.851687Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "text/plain": "<unstructured.documents.elements.NarrativeText at 0x3e11cae20>"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pdf_elements[11]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T18:03:18.673103Z",
     "start_time": "2024-10-02T18:03:18.653500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "data": {
      "text/plain": "'As per the assessment done by the Company, it expects to earn sufficient taxable profits based on improved business performance and reduction in interest costs in line with the plans for a reduction in net debt in subsequent years which enables the Company to utilize its carried forward unused tax losses with in permissible time as per income tax provisions.'"
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(raw_pdf_elements[11])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T18:03:21.835616Z",
     "start_time": "2024-10-02T18:03:21.818067Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "ss = tables[300:537]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T10:19:34.530441Z",
     "start_time": "2024-10-02T10:19:34.516886Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "237"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T10:19:39.363098Z",
     "start_time": "2024-10-02T10:19:39.338518Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "# Optional: Enforce a specific token size for texts\n",
    "# text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     chunk_size=4000, chunk_overlap=0\n",
    "# )\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=512, chunk_overlap=0\n",
    ")\n",
    "\n",
    "joined_texts = \"\\n\\n\".join(tables)\n",
    "texts_4k_token = text_splitter.split_text(joined_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:43:52.970121Z",
     "start_time": "2024-10-03T07:43:52.859820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "data": {
      "text/plain": "'Particulars I. ASSETS (1) NON-CURRENT ASSETS (a) Property, plant and equipment (b) Capital work-in-progress (c) Right of use assets (d) Other intangible assets (e) Intangible assets under development (f) Financial assets: (i) Investments in subsidiaries, joint ventures and associates (ii) Other investments (iii) Loans (iv) Other financial assets (g) Deferred tax assets (net) (h) Non-current tax assets (net) (i) Other non-current assets (2) CURRENT ASSETS (a) Inventories (b) Financial assets: (i) Investments (ii) Trade receivables (iii) Cash and cash equivalents (iv) Bank balances other than (iii) above (v) Loans (vi) Other financial assets (c) Current tax assets (net) (d) Other current assets (3) Assets classified as held-for-sale TOTAL ASSETS II. EQUITY AND LIABILITIES EQUITY (a) Equity share capital (b) Other equity LIABILITIES (1) NON-CURRENT LIABILITIES (a) Financial liabilities: (i) Borrowings (ii) Lease liabilities (iii) Other financial liabilities (b) Provisions (c) Deferred tax liabilities (net) (d) Other non-current liabilities (2) CURRENT LIABILITIES (a) Financial liabilities: (i) Borrowings (ii) Lease liabilities (iii) Trade payables (a) Total outstanding dues of micro and small enterprises (b) Total outstanding dues of creditors other than micro and small enterprises (c) Acceptances (iv) Other financial liabilities (b) Provisions (c) Current tax liabilities (net) (d) Other current liabilities TOTAL EQUITY AND LIABILITIES Notes 3 (b) 3 (d) 4 (b) 5 (b) 5 (c) 6 7 9 11 28 13 15 (b) 8 16 18 (b) 19 10 12 14 3 (c) 20 22 25 27 (b) 28 29 23 24 26 27 (c) 30 As at As at March 31, 2024 March 31, 2023 11,563.76 11,707.87 645.03 575.65 426.50 421.27 2,353.79'"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_4k_token[3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:43:53.536348Z",
     "start_time": "2024-10-03T07:43:53.527748Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_texts(texts_4k_token, embedding=embedder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:43:58.286523Z",
     "start_time": "2024-10-03T07:43:54.677764Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishavbose/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:44:00.061992Z",
     "start_time": "2024-10-03T07:43:59.046644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Document(metadata={}, page_content='Financial liabilities Derivatives other than in hedging relationship (at fair value) Derivatives in hedging relationship at fair value through profit or loss Other financial liabilities at amortised cost Total carrying value (a) Long-term borrowings (including Current maturities of long-term borrowings) - - 7,087.20 7,087.20 (b) Lease liabilities - - 419.60 419.60 (c) Short-term borrowings - - 6,683.84 6,683.84 (d) Trade payables - - 8,826.46 8,826.46 (e) Acceptances - - 4,508.01 4,508.01 (f) Other financial liabilities 75.95 1.57 1,321.26 1,398.78 Total 75.95 1.57 28,846.37 28,923.89 Total fair value 7,130.70 419.60 6,683.84 8,826.46 4,508.01 1,398.78 28,967.39'),\n Document(metadata={}, page_content='Financial liabilities Derivatives other than in hedging relationship (at fair value) Derivatives in hedging relationship at fair value through profit or loss Other financial liabilities at amortised cost Total carrying value (a) Long-term borrowings (including Current maturities of long-term borrowings) - - 7,087.20 7,087.20 (b) Lease liabilities - - 419.60 419.60 (c) Short-term borrowings - - 6,683.84 6,683.84 (d) Trade payables - - 8,826.46 8,826.46 (e) Acceptances - - 4,508.01 4,508.01 (f) Other financial liabilities 75.95 1.57 1,321.26 1,398.78 Total 75.95 1.57 28,846.37 28,923.89 Total fair value 7,130.70 419.60 6,683.84 8,826.46 4,508.01 1,398.78 28,967.39'),\n Document(metadata={}, page_content='Equity 30,175.44 22,660.54 Short-term borrowings and current maturities of long-term borrowings 8,535.37 8,426.74 Long-term borrowings 5,235.67 10,445.70 Total borrowings 13,771.04 18,872.44 Total capital (Debt + Equity) 43,946.48 41,532.98 Total equity as reported in balance sheet 30,143.05 22,469.85 Hedging reserve 2.50 (38.37) Cost of Hedge reserve 29.89 229.06 Equity as reported above 30,175.44 22,660.54 Financial assets Cash and other financial assets at amortised cost Investments - FVTOCI Investments - FVTPL Derivatives other than in hedging relationship at fair value through profit or loss Derivatives in hedging relationship at fair value through profit or loss Total carrying value (a) Investments-non-current - 1,586.12 - - - 1,586.12 (b) Investments-current 33.14 - 1,960.36 - - 1,993.50 (c) Trade receivables 2,765.16 - - - - 2,765.16 (d) Cash and cash equivalents 3,344.89 - - - - 3,344.89 (e) Other bank balances 1,806.07 - - - - 1,806.07 (f) Loans 234.08 - - - - 234.08 (g) Other financial assets 1,736.99 - - 315.60 325.25 2,377.84 Total fair value 1,586.12 1,993.50 2,765.16 3,344.89 1,806.07 234.08 2,377.84 Financial liabilities Derivatives other than in hedging relationship (at fair value) Derivatives in hedging relationship at fair value through profit or loss Other financial liabilities at amortised cost Total carrying value (a) Long-term borrowings (including Current maturities of long-term borrowings) - - 7,087.20 7,087.20 (b) Lease liabilities - - 419.60 419.60 (c) Short-term borrowings - - 6,683.84'),\n Document(metadata={}, page_content='As at March 31, 2024 Level 1 Level 2 Level 3 Financial liabilities not measured at fair value (a) Long-term borrowings (including current maturities of long term borrowing) 3,651.33 3,479.37 - (b) Short-term borrowings - 6,683.84 - (c) Option premium accrual - 73.69 - Total 3,651.33 10,236.90 - Total 7,130.70 6,683.84 73.69 13,888.23\\n\\nAs at March 31, 2023 Level 1 Level 2 Level 3 Financial liabilities not measured at fair value (a) Long-term borrowings (including current maturities of long term borrowing) 4,466.03 8,498.75 - (b) Short-term borrowings - 5,926.92 - (c) Option premium accrual - 226.93 - Total 4,466.03 14,652.60 - Total 12,964.78 5,926.92 226.93 19,118.63\\n\\nAmounts subject to an Gross amount recognised Gross amount recognised as set off in the balance sheet Net amount presented in the balance sheet enforceable master netting arrangement Cash Financial collateral instruments (received/ Net amount after offsetting pledged) Financial assets (a) Derivative financial instruments 640.85 - 640.85 (12.32) - 628.53 (b) Trade receivables 2,851.32 (86.16) 2,765.16 - - 2,765.16 (c) Loans-current 137.18 (4.99) 132.19 - - 132.19 Total 3,629.35 (91.15) 3,538.20 (12.32) - 3,525.88 Financial liabilities (a) Derivative financial instruments 77.52 - 77.52 (12.32) - 65.20 (b) Trade payables 8,917.61 (91.15) 8,826.46 - - 8,826.46 Total 8,995.13 (91.15) 8,903.98 (12.32) - 8,891.66'),\n Document(metadata={}, page_content='As at March 31, 2024 Level 1 Level 2 Level 3 Financial liabilities not measured at fair value (a) Long-term borrowings (including current maturities of long term borrowing) 3,651.33 3,479.37 - (b) Short-term borrowings - 6,683.84 - (c) Option premium accrual - 73.69 - Total 3,651.33 10,236.90 - Total 7,130.70 6,683.84 73.69 13,888.23\\n\\nAs at March 31, 2023 Level 1 Level 2 Level 3 Financial liabilities not measured at fair value (a) Long-term borrowings (including current maturities of long term borrowing) 4,466.03 8,498.75 - (b) Short-term borrowings - 5,926.92 - (c) Option premium accrual - 226.93 - Total 4,466.03 14,652.60 - Total 12,964.78 5,926.92 226.93 19,118.63\\n\\nAmounts subject to an Gross amount recognised Gross amount recognised as set off in the balance sheet Net amount presented in the balance sheet enforceable master netting arrangement Cash Financial collateral instruments (received/ Net amount after offsetting pledged) Financial assets (a) Derivative financial instruments 640.85 - 640.85 (12.32) - 628.53 (b) Trade receivables 2,851.32 (86.16) 2,765.16 - - 2,765.16 (c) Loans-current 137.18 (4.99) 132.19 - - 132.19 Total 3,629.35 (91.15) 3,538.20 (12.32) - 3,525.88 Financial liabilities (a) Derivative financial instruments 77.52 - 77.52 (12.32) - 65.20 (b) Trade payables 8,917.61 (91.15) 8,826.46 - - 8,826.46 Total 8,995.13 (91.15) 8,903.98 (12.32) - 8,891.66'),\n Document(metadata={}, page_content='Level 1 Level 2 Level 3 Financial liabilities not measured at fair value (a) Long-term borrowings (including current maturities of long term borrowing) 4,466.03 8,498.75 - (b) Short-term borrowings - 5,926.92 - (c) Option premium accrual - 226.93 - Total 4,466.03 14,652.60 - Total 12,964.78 5,926.92 226.93 19,118.63 Amounts subject to an Gross amount recognised Gross amount recognised as set off in the balance sheet Net amount presented in the balance sheet enforceable master netting arrangement Cash Financial collateral instruments (received/ Net amount after offsetting pledged) Financial assets (a) Derivative financial instruments 640.85 - 640.85 (12.32) - 628.53 (b) Trade receivables 2,851.32 (86.16) 2,765.16 - - 2,765.16 (c) Loans-current 137.18 (4.99) 132.19 - - 132.19 Total 3,629.35 (91.15) 3,538.20 (12.32) - 3,525.88 Financial liabilities (a) Derivative financial instruments 77.52 - 77.52 (12.32) - 65.20 (b) Trade payables 8,917.61 (91.15) 8,826.46 - - 8,826.46 Total 8,995.13 (91.15) 8,903.98 (12.32) - 8,891.66 Amounts subject to an Gross amount recognised Gross amount recognised as set off in the balance sheet Net amount presented in the balance sheet enforceable master netting arrangement Cash Financial collateral instruments (received/ Net amount after offsetting pledged) Financial assets (a) Derivative financial instruments 941.40 - 941.40 (39.68) - 901.72 (b) Trade receivables 2,616.43 (308.71) 2,307.72 - - 2,307.72 (c) Loans-current 103.01 (62.57) 40.44 - - 40.44 Total 3,660.84 (371.28) 3,289.56 (39.68)')]"
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Long-term borrowings (including Current maturities of long-term borrowings) in Financial liabilities\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T07:44:48.261568Z",
     "start_time": "2024-10-03T07:44:47.430054Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "# def format_docs(docs):\n",
    "#     limited_docs = docs[:2]  # Adjust N as needed\n",
    "#     return \"\\n\\n\".join(doc.page_content for doc in limited_docs)\n",
    "#     # return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "from tiktoken import get_encoding\n",
    "\n",
    "def format_docs(docs, max_tokens=120000, encoding_name=\"cl100k_base\"):\n",
    "    encoding = get_encoding(encoding_name)\n",
    "    formatted = \"\"\n",
    "    total_tokens = 0\n",
    "\n",
    "    for doc in docs:\n",
    "        doc_tokens = len(encoding.encode(doc.page_content))\n",
    "        # if total_tokens + doc_tokens > max_tokens:\n",
    "        #     print(\"Occurred\")\n",
    "        #     break\n",
    "        formatted += \"\\n\\n\" + doc.page_content\n",
    "        total_tokens += doc_tokens\n",
    "\n",
    "    return formatted\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T18:13:56.363357Z",
     "start_time": "2024-10-02T18:13:56.335913Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total non-current assets as of March 31, 2024, is 77,718.28 crores. This includes various categories such as property, plant and equipment, intangible assets, and investments. The figure shows an increase from the previous year's total non-current assets."
     ]
    }
   ],
   "source": [
    "# \"Percentage Increase in Income from investment related to subsidiaries, associates, and joint ventures from F23 to F24\"\n",
    "for chunk in rag_chain.stream(\"What is the total NON-CURRENT ASSETS as of March 31, 2024\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T18:14:12.736873Z",
     "start_time": "2024-10-02T18:13:57.305648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The net cash flow used in investing activities in 2024 was ₹(5,597.77) crores. This indicates a cash outflow as the company invested more in capital expenditures, acquisitions, and other financial activities than it received from sales or disposals in that year."
     ]
    }
   ],
   "source": [
    "# \"Percentage Increase in Income from investment related to subsidiaries, associates, and joint ventures from F23 to F24\"\n",
    "for chunk in rag_chain.stream(\"What was the Net cash flow used in investing activities in 2024?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T10:36:25.676518Z",
     "start_time": "2024-10-02T10:36:13.330852Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transactions with non-controlling interests for 2024 amount to a net cash outflow of ₹192.35 crores. This figure is part of the cash flow from financing activities. The details indicate the company engaged in transactions related to non-controlling interests, which impacted their cash flow for the year."
     ]
    }
   ],
   "source": [
    "# \"Percentage Increase in Income from investment related to subsidiaries, associates, and joint ventures from F23 to F24\"\n",
    "\n",
    "for chunk in rag_chain.stream(\"With respect to CASH FLOW FROM FINANCING ACTIVITIES, what is the  Transactions with non-controlling interests for 2024\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "    # time.sleep(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T10:46:51.107711Z",
     "start_time": "2024-10-02T10:46:38.014021Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    print(\"IT IS\")\n",
    "    print(html)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
    "\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    # \"https://razorpay.com/docs/api/\",\n",
    "    \"https://python.langchain.com/docs/how_to/message_history/\",\n",
    "    # extractor=bs4_extractor\n",
    "    # max_depth=3,\n",
    "    # use_async=False,\n",
    "    # extractor=None,\n",
    "    # metadata_extractor=None,\n",
    "    # exclude_dirs=(),\n",
    "    # timeout=10,\n",
    "    # check_response_status=True,\n",
    "    # continue_on_failure=True,\n",
    "    # prevent_outside=True,\n",
    "    # base_url=None,\n",
    "    # ...\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:44:39.020745Z",
     "start_time": "2024-10-04T06:44:39.014308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "docs1 = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:44:43.193443Z",
     "start_time": "2024-10-04T06:44:42.354834Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:44:43.821068Z",
     "start_time": "2024-10-04T06:44:43.810769Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'source': 'https://python.langchain.com/docs/how_to/message_history/',\n 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain',\n 'description': 'This guide assumes familiarity with the following concepts:',\n 'language': 'en'}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs1[0].metadata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:44:45.163536Z",
     "start_time": "2024-10-04T06:44:45.151914Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(metadata={'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nHow to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentIntegrationsAPI ReferenceMoreContributingPeopleLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\\uf8ffüí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a Simple LLM Application with LCELBuild a Query Analysis SystemBuild a ChatbotConversational RAGBuild an Extraction ChainBuild an AgentTaggingdata_generationBuild a Local RAG ApplicationBuild a PDF ingestion and Question/Answering systemBuild a Retrieval Augmented Generation (RAG) AppVector stores and retrieversBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to map values to a graph databaseHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to best prompt for Graph-RAGHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to split by HTML headerHow to split by HTML sectionsHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables as ToolsHow to create custom callback handlersHow to create a custom chat model classHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data directly to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideEcosystem\\uf8ffü¶ú\\uf8ffüõ†Ô∏è LangSmith\\uf8ffü¶ú\\uf8ffüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurityHow-to guidesHow to add message historyOn this pageHow to add message history\\nPrerequisitesThis guide assumes familiarity with the following concepts:\\nChaining runnables\\nPrompt templates\\nChat Messages\\nLangGraph persistence\\n\\nnoteThis guide previously covered the RunnableWithMessageHistory abstraction. You can access this version of the guide in the v0.2 docs.As of the v0.3 release of LangChain, we recommend that LangChain users take advantage of LangGraph persistence to incorporate memory into new LangChain applications.If your code is already relying on RunnableWithMessageHistory or BaseChatMessageHistory, you do not need to make any changes. We do not plan on deprecating this functionality in the near future as it works for simple chat applications and any code that uses RunnableWithMessageHistory will continue to work as expected.Please see How to migrate to LangGraph Memory for more details.\\nPassing conversation state into and out a chain is vital when building a chatbot. LangGraph implements a built-in persistence layer, allowing chain states to be automatically persisted in memory, or external backends such as SQLite, Postgres or Redis. Details can be found in the LangGraph persistence documentation.\\nIn this guide we demonstrate how to add persistence to arbitrary LangChain runnables by wrapping them in a minimal LangGraph application. This lets us persist the message history and other elements of the chain\\'s state, simplifying the development of multi-turn applications. It also supports multiple threads, enabling a single application to interact separately with multiple users.\\nSetup‚Äã\\nLet\\'s initialize a chat model:\\n\\nOpenAIAnthropicAzureGoogleCohereNVIDIAFireworksAIGroqMistralAITogetherAIpip install -qU langchain-openaiimport getpassimport osos.environ[\"OPENAI_API_KEY\"] = getpass.getpass()from langchain_openai import ChatOpenAIllm = ChatOpenAI(model=\"gpt-4o-mini\")pip install -qU langchain-anthropicimport getpassimport osos.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass()from langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")pip install -qU langchain-openaiimport getpassimport osos.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass()from langchain_openai import AzureChatOpenAIllm = AzureChatOpenAI(    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],)pip install -qU langchain-google-vertexaiimport getpassimport osos.environ[\"GOOGLE_API_KEY\"] = getpass.getpass()from langchain_google_vertexai import ChatVertexAIllm = ChatVertexAI(model=\"gemini-1.5-flash\")pip install -qU langchain-cohereimport getpassimport osos.environ[\"COHERE_API_KEY\"] = getpass.getpass()from langchain_cohere import ChatCoherellm = ChatCohere(model=\"command-r-plus\")pip install -qU langchain-nvidia-ai-endpointsimport getpassimport osos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()from langchain import ChatNVIDIAllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")pip install -qU langchain-fireworksimport getpassimport osos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()from langchain_fireworks import ChatFireworksllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")pip install -qU langchain-groqimport getpassimport osos.environ[\"GROQ_API_KEY\"] = getpass.getpass()from langchain_groq import ChatGroqllm = ChatGroq(model=\"llama3-8b-8192\")pip install -qU langchain-mistralaiimport getpassimport osos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()from langchain_mistralai import ChatMistralAIllm = ChatMistralAI(model=\"mistral-large-latest\")pip install -qU langchain-openaiimport getpassimport osos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()from langchain_openai import ChatOpenAIllm = ChatOpenAI(    base_url=\"https://api.together.xyz/v1\",    api_key=os.environ[\"TOGETHER_API_KEY\"],    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",)\\nExample: message inputs‚Äã\\nAdding memory to a chat model provides a simple example. Chat models accept a list of messages as input and output a message. LangGraph includes a built-in MessagesState that we can use for this purpose.\\nBelow, we:\\n\\nDefine the graph state to be a list of messages;\\nAdd a single node to the graph that calls a chat model;\\nCompile the graph with an in-memory checkpointer to store messages between runs.\\n\\ninfoThe output of a LangGraph application is its state. This can be any Python type, but in this context it will typically be a TypedDict that matches the schema of your runnable.\\nfrom langchain_core.messages import HumanMessagefrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.graph import START, MessagesState, StateGraph# Define a new graphworkflow = StateGraph(state_schema=MessagesState)# Define the function that calls the modeldef call_model(state: MessagesState):    response = llm.invoke(state[\"messages\"])    # Update message history with response:    return {\"messages\": response}# Define the (single) node in the graphworkflow.add_edge(START, \"model\")workflow.add_node(\"model\", call_model)# Add memorymemory = MemorySaver()app = workflow.compile(checkpointer=memory)API Reference:HumanMessage | MemorySaver | StateGraph\\nWhen we run the application, we pass in a configuration dict that specifies a thread_id. This ID is used to distinguish conversational threads (e.g., between different users).\\nconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}\\nWe can then invoke the application:\\nquery = \"Hi! I\\'m Bob.\"input_messages = [HumanMessage(query)]output = app.invoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()  # output contains all messages in state\\n==================================\\x1b[1m Ai Message \\x1b[0m==================================It\\'s nice to meet you, Bob! I\\'m Claude, an AI assistant created by Anthropic. How can I help you today?\\nquery = \"What\\'s my name?\"input_messages = [HumanMessage(query)]output = app.invoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()\\n==================================\\x1b[1m Ai Message \\x1b[0m==================================Your name is Bob, as you introduced yourself at the beginning of our conversation.\\nNote that states are separated for different threads. If we issue the same query to a thread with a new thread_id, the model indicates that it does not know the answer:\\nquery = \"What\\'s my name?\"config = {\"configurable\": {\"thread_id\": \"abc234\"}}input_messages = [HumanMessage(query)]output = app.invoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()\\n==================================\\x1b[1m Ai Message \\x1b[0m==================================I\\'m afraid I don\\'t actually know your name. As an AI assistant, I don\\'t have personal information about you unless you provide it to me directly.\\nExample: dictionary inputs‚Äã\\nLangChain runnables often accept multiple inputs via separate keys in a single dict argument. A common example is a prompt template with multiple parameters.\\nWhereas before our runnable was a chat model, here we chain together a prompt template and chat model.\\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholderprompt = ChatPromptTemplate.from_messages(    [        (\"system\", \"Answer in {language}.\"),        MessagesPlaceholder(variable_name=\"messages\"),    ])runnable = prompt | llmAPI Reference:ChatPromptTemplate | MessagesPlaceholder\\nFor this scenario, we define the graph state to include these parameters (in addition to the message history). We then define a single-node graph in the same way as before.\\nNote that in the below state:\\n\\nUpdates to the messages list will append messages;\\nUpdates to the language string will overwrite the string.\\n\\nfrom typing import Sequencefrom langchain_core.messages import BaseMessagefrom langgraph.graph.message import add_messagesfrom typing_extensions import Annotated, TypedDictclass State(TypedDict):    messages: Annotated[Sequence[BaseMessage], add_messages]    language: strworkflow = StateGraph(state_schema=State)def call_model(state: State):    response = runnable.invoke(state)    # Update message history with response:    return {\"messages\": [response]}workflow.add_edge(START, \"model\")workflow.add_node(\"model\", call_model)memory = MemorySaver()app = workflow.compile(checkpointer=memory)API Reference:BaseMessage | add_messages\\nconfig = {\"configurable\": {\"thread_id\": \"abc345\"}}input_dict = {    \"messages\": [HumanMessage(\"Hi, I\\'m Bob.\")],    \"language\": \"Spanish\",}output = app.invoke(input_dict, config)output[\"messages\"][-1].pretty_print()\\n==================================\\x1b[1m Ai Message \\x1b[0m==================================¬°Hola, Bob! Es un placer conocerte.\\nManaging message history‚Äã\\nThe message history (and other elements of the application state) can be accessed via .get_state:\\nstate = app.get_state(config).valuesprint(f\\'Language: {state[\"language\"]}\\')for message in state[\"messages\"]:    message.pretty_print()\\nLanguage: Spanish================================\\x1b[1m Human Message \\x1b[0m=================================Hi, I\\'m Bob.==================================\\x1b[1m Ai Message \\x1b[0m==================================¬°Hola, Bob! Es un placer conocerte.\\nWe can also update the state via .update_state. For example, we can manually append a new message:\\nfrom langchain_core.messages import HumanMessage_ = app.update_state(config, {\"messages\": [HumanMessage(\"Test\")]})API Reference:HumanMessage\\nstate = app.get_state(config).valuesprint(f\\'Language: {state[\"language\"]}\\')for message in state[\"messages\"]:    message.pretty_print()\\nLanguage: Spanish================================\\x1b[1m Human Message \\x1b[0m=================================Hi, I\\'m Bob.==================================\\x1b[1m Ai Message \\x1b[0m==================================¬°Hola, Bob! Es un placer conocerte.================================\\x1b[1m Human Message \\x1b[0m=================================Test\\nFor details on managing state, including deleting messages, see the LangGraph documentation:\\n\\nHow to delete messages\\nHow to view and update past graph state\\nEdit this pageWas this page helpful?You can also leave detailed feedback on GitHub.PreviousHow to merge consecutive messages of the same typeNextHow to migrate from legacy LangChain agents to LangGraphSetupExample: message inputsExample: dictionary inputsManaging message historyCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2024 LangChain, Inc.\\n\\n')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs1[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:44:46.795279Z",
     "start_time": "2024-10-04T06:44:46.784695Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Optional: Enforce a specific token size for texts\n",
    "# text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     chunk_size=4000, chunk_overlap=0\n",
    "# )\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=256, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# joined_texts = \"\\n\\n\".join(tables)\n",
    "docs_token = text_splitter.split_documents(docs1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:45:17.837371Z",
     "start_time": "2024-10-04T06:45:08.360406Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(metadata={'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en'}, page_content='infoThe output of a LangGraph application is its state. This can be any Python type, but in this context it will typically be a TypedDict that matches the schema of your runnable.\\nfrom langchain_core.messages import HumanMessagefrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.graph import START, MessagesState, StateGraph# Define a new graphworkflow = StateGraph(state_schema=MessagesState)# Define the function that calls the modeldef call_model(state: MessagesState):    response = llm.invoke(state[\"messages\"])    # Update message history with response:    return {\"messages\": response}# Define the (single) node in the graphworkflow.add_edge(START, \"model\")workflow.add_node(\"model\", call_model)# Add memorymemory = MemorySaver()app = workflow.compile(checkpointer=memory)API Reference:HumanMessage | MemorySaver | StateGraph\\nWhen we run the application, we pass in a configuration dict that specifies a thread_id. This ID is used to distinguish conversational threads (e.g., between different users).\\nconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}\\nWe can then invoke the application:')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_token[15]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:45:28.682861Z",
     "start_time": "2024-10-04T06:45:28.677468Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(docs_token, embedding=embedder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:45:52.427228Z",
     "start_time": "2024-10-04T06:45:50.877151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "outputs": [],
   "source": [
    "docs_token=docs_token[0:25000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T12:34:24.676884Z",
     "start_time": "2024-10-03T12:34:24.627212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(metadata={'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en'}, page_content='infoThe output of a LangGraph application is its state. This can be any Python type, but in this context it will typically be a TypedDict that matches the schema of your runnable.\\nfrom langchain_core.messages import HumanMessagefrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.graph import START, MessagesState, StateGraph# Define a new graphworkflow = StateGraph(state_schema=MessagesState)# Define the function that calls the modeldef call_model(state: MessagesState):    response = llm.invoke(state[\"messages\"])    # Update message history with response:    return {\"messages\": response}# Define the (single) node in the graphworkflow.add_edge(START, \"model\")workflow.add_node(\"model\", call_model)# Add memorymemory = MemorySaver()app = workflow.compile(checkpointer=memory)API Reference:HumanMessage | MemorySaver | StateGraph\\nWhen we run the application, we pass in a configuration dict that specifies a thread_id. This ID is used to distinguish conversational threads (e.g., between different users).\\nconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}\\nWe can then invoke the application:')"
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_token[15]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:41:21.493335Z",
     "start_time": "2024-10-04T06:41:21.474664Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "embedder = OpenAIEmbeddings()\n",
    "# vectorstore = Chroma(embedding_function=embedder)\n",
    "# Define Batch Size (Adjust based on your rate limits)\n",
    "BATCH_SIZE = 200  # Number of documents per batch\n",
    "\n",
    "# Split documents into batches\n",
    "def chunk_documents(docs, batch_size):\n",
    "    for i in range(0, len(docs), batch_size):\n",
    "        yield docs[i:i + batch_size]\n",
    "\n",
    "# Function to embed and add to vector store\n",
    "def embed_and_store(docs_batch):\n",
    "    try:\n",
    "        # embeddings = embedder.embed_documents([doc.page_content for doc in docs_batch])\n",
    "        vectorstore.add_documents(docs_batch)\n",
    "    except Exception as e:\n",
    "        print(f\"Error embedding batch: {e}\")\n",
    "        time.sleep(5)  # Wait before retrying\n",
    "        embed_and_store(docs_batch)  # Retry\n",
    "\n",
    "# Process all documents in batches\n",
    "for batch in chunk_documents(docs_token, BATCH_SIZE):\n",
    "    embed_and_store(batch)\n",
    "    time.sleep(1)  # Delay between batches to respect rate limits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T12:44:19.781291Z",
     "start_time": "2024-10-03T12:34:37.907686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 8})\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:46:08.643559Z",
     "start_time": "2024-10-04T06:46:08.635441Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[\n",
    "\tHumanMessagePromptTemplate(\n",
    "\t\tprompt=PromptTemplate(\n",
    "\t\t\tinput_variables=['context', 'question'],\n",
    "\t\t\tinput_types={},\n",
    "\t\t\tpartial_variables={},\n",
    "\t\t\ttemplate=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Try to answer in detail in not less than 100 words.It would be great if you can also provide snippet of code in python.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n",
    "\t\t),\n",
    "\tadditional_kwargs={})\n",
    "\t]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:46:18.659328Z",
     "start_time": "2024-10-04T06:46:18.640187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(metadata={'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en', 'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain'}, page_content='How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain'),\n Document(metadata={'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en', 'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain'}, page_content='How to delete messages\\nHow to view and update past graph state\\nEdit this pageWas this page helpful?You can also leave detailed feedback on GitHub.PreviousHow to merge consecutive messages of the same typeNextHow to migrate from legacy LangChain agents to LangGraphSetupExample: message inputsExample: dictionary inputsManaging message historyCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2024 LangChain, Inc.'),\n Document(metadata={'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en', 'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain'}, page_content='noteThis guide previously covered the RunnableWithMessageHistory abstraction. You can access this version of the guide in the v0.2 docs.As of the v0.3 release of LangChain, we recommend that LangChain users take advantage of LangGraph persistence to incorporate memory into new LangChain applications.If your code is already relying on RunnableWithMessageHistory or BaseChatMessageHistory, you do not need to make any changes. We do not plan on deprecating this functionality in the near future as it works for simple chat applications and any code that uses RunnableWithMessageHistory will continue to work as expected.Please see How to migrate to LangGraph Memory for more details.\\nPassing conversation state into and out a chain is vital when building a chatbot. LangGraph implements a built-in persistence layer, allowing chain states to be automatically persisted in memory, or external backends such as SQLite, Postgres or Redis. Details can be found in the LangGraph persistence documentation.'),\n Document(metadata={'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en', 'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain'}, page_content='LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurityHow-to guidesHow to add message historyOn this pageHow to add message history'),\n Document(metadata={'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en', 'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain'}, page_content=\"In this guide we demonstrate how to add persistence to arbitrary LangChain runnables by wrapping them in a minimal LangGraph application. This lets us persist the message history and other elements of the chain's state, simplifying the development of multi-turn applications. It also supports multiple threads, enabling a single application to interact separately with multiple users.\\nSetup‚Äã\\nLet's initialize a chat model:\"),\n Document(metadata={'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en', 'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain'}, page_content='Example: message inputs‚Äã\\nAdding memory to a chat model provides a simple example. Chat models accept a list of messages as input and output a message. LangGraph includes a built-in MessagesState that we can use for this purpose.\\nBelow, we:'),\n Document(metadata={'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en', 'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain'}, page_content='Updates to the messages list will append messages;\\nUpdates to the language string will overwrite the string.'),\n Document(metadata={'description': 'This guide assumes familiarity with the following concepts:', 'language': 'en', 'source': 'https://python.langchain.com/docs/how_to/message_history/', 'title': 'How to add message history | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain'}, page_content='from typing import Sequencefrom langchain_core.messages import BaseMessagefrom langgraph.graph.message import add_messagesfrom typing_extensions import Annotated, TypedDictclass State(TypedDict):    messages: Annotated[Sequence[BaseMessage], add_messages]    language: strworkflow = StateGraph(state_schema=State)def call_model(state: State):    response = runnable.invoke(state)    # Update message history with response:    return {\"messages\": [response]}workflow.add_edge(START, \"model\")workflow.add_node(\"model\", call_model)memory = MemorySaver()app = workflow.compile(checkpointer=memory)API Reference:BaseMessage | add_messages\\nconfig = {\"configurable\": {\"thread_id\": \"abc345\"}}input_dict = {    \"messages\": [HumanMessage(\"Hi, I\\'m Bob.\")],    \"language\": \"Spanish\",}output = app.invoke(input_dict, config)output[\"messages\"][-1].pretty_print()\\n==================================\\x1b[1m Ai Message \\x1b[0m==================================¬°Hola, Bob! Es un placer conocerte.\\nManaging message history‚Äã\\nThe message history (and other elements of the application state) can be accessed via .get_state:')]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How to mange message history?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T06:46:22.057394Z",
     "start_time": "2024-10-04T06:46:20.889524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"messages\": history ,\"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "# for chunk in rag_chain.stream(\"What is the request parameters for create order api?\"):\n",
    "#     print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T07:48:04.141137Z",
     "start_time": "2024-10-04T07:48:04.116168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your last question appears to be related to asking for information about your name. In the context provided, you engaged with an AI assistant named Claude, where you stated, \"Hi! I'm Bob.\" Subsequently, you inquired, \"What's my name?\" The AI successfully retrieved that you had introduced yourself as Bob at the start of the conversation. This reflects a typical interaction with an AI, where it utilizes memory or context from earlier parts of the dialogue to provide accurate responses. \n",
      "\n",
      "This scenario demonstrates how conversational AI can track user inputs and maintain context throughout a session. If you're implementing a similar feature in Python using a framework like LangChain, you would structure your code to handle user messages and maintain state effectively. Here is a snippet of code that illustrates how you could set up a simple interaction with an AI model, tracking user input:\n",
      "\n",
      "```python\n",
      "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
      "\n",
      "# Initialize the chat prompt template\n",
      "prompt = ChatPromptTemplate.from_messages(\n",
      "    [\n",
      "        (\"system\", \"You are a helpful assistant.\"),\n",
      "        MessagesPlaceholder(variable_name=\"messages\"),\n",
      "    ]\n",
      ")\n",
      "\n",
      "# Function to simulate conversation\n",
      "def chat_with_ai(user_input):\n",
      "    input_messages = [HumanMessage(user_input)]\n",
      "    output = app.invoke({\"messages\": input_messages}, config)\n",
      "    return output[\"messages\"][-1].pretty_print()\n",
      "\n",
      "# Example interaction\n",
      "print(chat_with_ai(\"Hi! I'm Bob.\"))\n",
      "print(chat_with_ai(\"What's my name?\"))\n",
      "```\n",
      "\n",
      "This code sets up a basic template for handling user messages and invoking the AI model to respond based on past interactions, allowing for a coherent conversation."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"Can you tell me what my last question was related to? \"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T07:51:34.259959Z",
     "start_time": "2024-10-04T07:51:27.407005Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "ss_output = \"\"\"\n",
    "Managing message history in applications, particularly in chatbots or conversational AI systems, is essential for maintaining context and ensuring coherent interactions. Using frameworks like LangChain, you can efficiently handle message history through built-in features that support persistence. With the LangGraph application, you can wrap your runnable components to retain the state of messages across multiple interactions.\n",
    "\n",
    "To manage message history, you would typically initialize a chat model, which accepts a list of messages as input. The LangGraph framework provides a `MessagesState` to facilitate this. You can append new messages and overwrite existing ones as needed. This is particularly useful for multi-turn conversations, where maintaining the context of the dialogue is crucial. You can also implement a persistence layer that saves the message history in memory or external databases like SQLite, Postgres, or Redis.\n",
    "\n",
    "Here’s an example of how to manage message history in Python using LangChain:\n",
    "\n",
    "```python\n",
    "from typing import Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    response = runnable.invoke(state)\n",
    "    # Update message history with the response\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "input_dict = {\n",
    "    \"messages\": [HumanMessage(\"Hi, I'm Bob.\")],\n",
    "    \"language\": \"Spanish\",\n",
    "}\n",
    "\n",
    "output = app.invoke(input_dict, config)\n",
    "output[\"messages\"][-1].pretty_print()\n",
    "```\n",
    "\n",
    "In this code, we define a state that includes a list of messages and a language. The `call_model` function is responsible for invoking the model and updating the message history. Finally, we compile the workflow, allowing for the invocation of the message history management within a chat context. The output can be accessed and displayed as needed.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T07:44:20.090860Z",
     "start_time": "2024-10-04T07:44:20.057522Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def history(docs):\n",
    "    return [('user', \"How to mange message history?\"),\n",
    "           # ('system', ss_output)\n",
    "            ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T08:48:15.848164Z",
     "start_time": "2024-10-04T08:48:15.834183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "prompt_test = MessagesPlaceholder(\"history\", optional=True)\n",
    "history1 = [('user', \"How to mange message history?\"),\n",
    "           # ('ai', ss_output)\n",
    "            ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T07:50:36.703075Z",
     "start_time": "2024-10-04T07:50:36.668125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T07:51:23.394569Z",
     "start_time": "2024-10-04T07:51:23.382830Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(input_variables=['messages', 'context', 'question'], input_types={}, partial_variables={}, messages=[\n",
    "\tHumanMessagePromptTemplate(\n",
    "\t\tprompt=PromptTemplate(\n",
    "\t\t\tinput_variables=['messages','context', 'question'],\n",
    "\t\t\tinput_types={},\n",
    "\t\t\tpartial_variables={},\n",
    "\t\t\ttemplate=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Try to answer in detail in not less than 100 words.It would be great if you can also provide snippet of code in python.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n",
    "\t\t),\n",
    "\tadditional_kwargs={}),\n",
    "    ('user', \"How to mange message history?\"),\n",
    "    # ('ai', ss_output)\n",
    "\t]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T08:48:18.418221Z",
     "start_time": "2024-10-04T08:48:18.396194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"messages\": history ,\"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T08:48:19.607603Z",
     "start_time": "2024-10-04T08:48:19.594410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Managing message history in a conversational AI system is crucial for maintaining context and continuity in interactions. This can be achieved by storing previous messages and utilizing them in subsequent exchanges to provide more coherent responses. \n",
      "\n",
      "In a typical implementation, each message sent by the user and the corresponding reply from the AI can be logged in a structured format, such as a list or a database. This history can then be referenced whenever a new query comes in, allowing the system to consider past interactions and respond appropriately. \n",
      "\n",
      "Here’s a simple example in Python using a list to store message history:\n",
      "\n",
      "```python\n",
      "class Chatbot:\n",
      "    def __init__(self):\n",
      "        self.message_history = []\n",
      "\n",
      "    def add_message(self, user_message):\n",
      "        self.message_history.append({'user': user_message})\n",
      "        ai_response = self.generate_response(user_message)\n",
      "        self.message_history.append({'ai': ai_response})\n",
      "        return ai_response\n",
      "\n",
      "    def generate_response(self, user_message):\n",
      "        # This is a placeholder for actual AI response generation logic\n",
      "        return f\"Echo: {user_message}\"\n",
      "\n",
      "    def get_history(self):\n",
      "        return self.message_history\n",
      "\n",
      "# Example usage\n",
      "chatbot = Chatbot()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m rag_chain\u001B[38;5;241m.\u001B[39mstream(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan you tell me what my last question was related to? \u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(chunk, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, flush\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:3403\u001B[0m, in \u001B[0;36mRunnableSequence.stream\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3397\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[1;32m   3398\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3399\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   3400\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3401\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3402\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3403\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(\u001B[38;5;28miter\u001B[39m([\u001B[38;5;28minput\u001B[39m]), config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:3390\u001B[0m, in \u001B[0;36mRunnableSequence.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3384\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m   3385\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3386\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[1;32m   3387\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3388\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3389\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3390\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m   3391\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   3392\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform,\n\u001B[1;32m   3393\u001B[0m         patch_config(config, run_name\u001B[38;5;241m=\u001B[39m(config \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m   3394\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3395\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:2194\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2192\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2193\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 2194\u001B[0m         chunk: Output \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2195\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   2196\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:3353\u001B[0m, in \u001B[0;36mRunnableSequence._transform\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m   3350\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3351\u001B[0m         final_pipeline \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39mtransform(final_pipeline, config)\n\u001B[0;32m-> 3353\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m final_pipeline\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/output_parsers/transform.py:64\u001B[0m, in \u001B[0;36mBaseTransformOutputParser.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Union[\u001B[38;5;28mstr\u001B[39m, BaseMessage]],\n\u001B[1;32m     51\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m     53\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T]:\n\u001B[1;32m     54\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Transform the input into the output format.\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;124;03m        The transformed output.\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m     65\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform, config, run_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparser\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     66\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:2194\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2192\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2193\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 2194\u001B[0m         chunk: Output \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2195\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   2196\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/output_parsers/transform.py:29\u001B[0m, in \u001B[0;36mBaseTransformOutputParser._transform\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Iterator[Union[\u001B[38;5;28mstr\u001B[39m, BaseMessage]]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T]:\n\u001B[0;32m---> 29\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28minput\u001B[39m:\n\u001B[1;32m     30\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunk, BaseMessage):\n\u001B[1;32m     31\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparse_result([ChatGeneration(message\u001B[38;5;241m=\u001B[39mchunk)])\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/runnables/base.py:1428\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1425\u001B[0m             final \u001B[38;5;241m=\u001B[39m ichunk\n\u001B[1;32m   1427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m got_first_val:\n\u001B[0;32m-> 1428\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(final, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:418\u001B[0m, in \u001B[0;36mBaseChatModel.stream\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    412\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(\n\u001B[1;32m    413\u001B[0m         e,\n\u001B[1;32m    414\u001B[0m         response\u001B[38;5;241m=\u001B[39mLLMResult(\n\u001B[1;32m    415\u001B[0m             generations\u001B[38;5;241m=\u001B[39m[[generation]] \u001B[38;5;28;01mif\u001B[39;00m generation \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m    416\u001B[0m         ),\n\u001B[1;32m    417\u001B[0m     )\n\u001B[0;32m--> 418\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    420\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_end(LLMResult(generations\u001B[38;5;241m=\u001B[39m[[generation]]))\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:398\u001B[0m, in \u001B[0;36mBaseChatModel.stream\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    395\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrate_limiter\u001B[38;5;241m.\u001B[39macquire(blocking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    397\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 398\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    399\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m chunk\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mid \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    400\u001B[0m             chunk\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mid \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_manager\u001B[38;5;241m.\u001B[39mrun_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:642\u001B[0m, in \u001B[0;36mBaseChatOpenAI._stream\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m response:\n\u001B[1;32m    641\u001B[0m     is_first_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 642\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m response:\n\u001B[1;32m    643\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunk, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    644\u001B[0m             chunk \u001B[38;5;241m=\u001B[39m chunk\u001B[38;5;241m.\u001B[39mmodel_dump()\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:46\u001B[0m, in \u001B[0;36mStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[_T]:\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator:\n\u001B[1;32m     47\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m item\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:58\u001B[0m, in \u001B[0;36mStream.__stream__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m process_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39m_process_response_data\n\u001B[1;32m     56\u001B[0m iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_events()\n\u001B[0;32m---> 58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sse \u001B[38;5;129;01min\u001B[39;00m iterator:\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sse\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[DONE]\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     60\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:50\u001B[0m, in \u001B[0;36mStream._iter_events\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_iter_events\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[ServerSentEvent]:\n\u001B[0;32m---> 50\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoder\u001B[38;5;241m.\u001B[39miter_bytes(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39miter_bytes())\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:280\u001B[0m, in \u001B[0;36mSSEDecoder.iter_bytes\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21miter_bytes\u001B[39m(\u001B[38;5;28mself\u001B[39m, iterator: Iterator[\u001B[38;5;28mbytes\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[ServerSentEvent]:\n\u001B[1;32m    279\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it & yield every event encountered\"\"\"\u001B[39;00m\n\u001B[0;32m--> 280\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_chunks(iterator):\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;66;03m# Split before decoding so splitlines() only uses \\r and \\n\u001B[39;00m\n\u001B[1;32m    282\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m raw_line \u001B[38;5;129;01min\u001B[39;00m chunk\u001B[38;5;241m.\u001B[39msplitlines():\n\u001B[1;32m    283\u001B[0m             line \u001B[38;5;241m=\u001B[39m raw_line\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/openai/_streaming.py:291\u001B[0m, in \u001B[0;36mSSEDecoder._iter_chunks\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\u001B[39;00m\n\u001B[1;32m    290\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 291\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m iterator:\n\u001B[1;32m    292\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m chunk\u001B[38;5;241m.\u001B[39msplitlines(keepends\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    293\u001B[0m         data \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m line\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpx/_models.py:831\u001B[0m, in \u001B[0;36mResponse.iter_bytes\u001B[0;34m(self, chunk_size)\u001B[0m\n\u001B[1;32m    829\u001B[0m chunker \u001B[38;5;241m=\u001B[39m ByteChunker(chunk_size\u001B[38;5;241m=\u001B[39mchunk_size)\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request):\n\u001B[0;32m--> 831\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m raw_bytes \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miter_raw():\n\u001B[1;32m    832\u001B[0m         decoded \u001B[38;5;241m=\u001B[39m decoder\u001B[38;5;241m.\u001B[39mdecode(raw_bytes)\n\u001B[1;32m    833\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunker\u001B[38;5;241m.\u001B[39mdecode(decoded):\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpx/_models.py:885\u001B[0m, in \u001B[0;36mResponse.iter_raw\u001B[0;34m(self, chunk_size)\u001B[0m\n\u001B[1;32m    882\u001B[0m chunker \u001B[38;5;241m=\u001B[39m ByteChunker(chunk_size\u001B[38;5;241m=\u001B[39mchunk_size)\n\u001B[1;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request):\n\u001B[0;32m--> 885\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m raw_stream_bytes \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream:\n\u001B[1;32m    886\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_bytes_downloaded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(raw_stream_bytes)\n\u001B[1;32m    887\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunker\u001B[38;5;241m.\u001B[39mdecode(raw_stream_bytes):\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpx/_client.py:127\u001B[0m, in \u001B[0;36mBoundSyncStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m typing\u001B[38;5;241m.\u001B[39mIterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream:\n\u001B[1;32m    128\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpx/_transports/default.py:116\u001B[0m, in \u001B[0;36mResponseStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m typing\u001B[38;5;241m.\u001B[39mIterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m part \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_httpcore_stream:\n\u001B[1;32m    117\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m part\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:367\u001B[0m, in \u001B[0;36mPoolByteStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    366\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:363\u001B[0m, in \u001B[0;36mPoolByteStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 363\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m part \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stream:\n\u001B[1;32m    364\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m part\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:349\u001B[0m, in \u001B[0;36mHTTP11ConnectionByteStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ShieldCancellation():\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m--> 349\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:341\u001B[0m, in \u001B[0;36mHTTP11ConnectionByteStream.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_body\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request, kwargs):\n\u001B[0;32m--> 341\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39m_receive_response_body(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    342\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    344\u001B[0m     \u001B[38;5;66;03m# If we get an exception while streaming the response,\u001B[39;00m\n\u001B[1;32m    345\u001B[0m     \u001B[38;5;66;03m# we want to close the response (and possibly the connection)\u001B[39;00m\n\u001B[1;32m    346\u001B[0m     \u001B[38;5;66;03m# before raising that exception.\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:210\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_response_body\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    207\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeouts\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 210\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mData):\n\u001B[1;32m    212\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mbytes\u001B[39m(event\u001B[38;5;241m.\u001B[39mdata)\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:224\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_event\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    221\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[0;32m--> 224\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_network_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mtheir_state \u001B[38;5;241m==\u001B[39m h11\u001B[38;5;241m.\u001B[39mSEND_RESPONSE:\n",
      "File \u001B[0;32m~/Documents/github_projects/slackBot/venv/lib/python3.9/site-packages/httpcore/_backends/sync.py:126\u001B[0m, in \u001B[0;36mSyncStream.read\u001B[0;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001B[0m, in \u001B[0;36mSSLSocket.recv\u001B[0;34m(self, buflen, flags)\u001B[0m\n\u001B[1;32m   1222\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1223\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1224\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1225\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1226\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuflen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1228\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv(buflen, flags)\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1099\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1101\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1102\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SSLError \u001B[38;5;28;01mas\u001B[39;00m x:\n\u001B[1;32m   1103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m SSL_ERROR_EOF \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuppress_ragged_eofs:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"Can you tell me what my last question was related to? \"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-04T08:48:26.112007Z",
     "start_time": "2024-10-04T08:48:21.881588Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
